{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF to Markdown Pipeline - Usage Example Notebook\n",
    "================================================\n",
    "\n",
    "This notebook demonstrates how to use the high-fidelity PDF to Markdown pipeline\n",
    "with LangChain Ollama integration.\n",
    "\n",
    "Prerequisites:\n",
    "- Ollama server running with a vision model (e.g., llama3.2-vision:11b)\n",
    "- Required Python packages: PyMuPDF, langchain-ollama, PIL, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-ollama) (0.5.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.60 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-ollama) (0.3.68)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (4.14.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.11.7)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from ollama<1.0.0,>=0.4.8->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simple_vision_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Install required packages (run once)\u001b[39;00m\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall pymupdf langchain-ollama pillow\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msimple_vision_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_pdf_to_markdown_simple, SimplePDFToMarkdownPipeline\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'simple_vision_pipeline'"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install pymupdf langchain-ollama pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple pipeline (vision only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vision_parser.parser import convert_pdf_to_markdown_simple, SimplePDFToMarkdownPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Vision-Only PDF Conversion ===\n",
      "2025-07-06 11:16:54,418 - src.vision_parser.parser - INFO - Connected to Ollama at http://192.168.100.80:1818\n",
      "2025-07-06 11:16:54,418 - src.vision_parser.parser - INFO - VisionProcessor initialized with model: qwen2.5vl:3b-q4_K_M\n",
      "2025-07-06 11:16:54,457 - src.vision_parser.parser - INFO - Processing PDF with 4 pages...\n",
      "2025-07-06 11:16:54,457 - src.vision_parser.parser - INFO - Processing page 1/4\n",
      "2025-07-06 11:17:15,990 - src.vision_parser.parser - ERROR - Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "2025-07-06 11:17:15,990 - src.vision_parser.parser - WARNING - Warning: Error processing page 1: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "2025-07-06 11:17:15,990 - src.vision_parser.parser - INFO - Processing page 2/4\n",
      "2025-07-06 11:17:37,362 - src.vision_parser.parser - ERROR - Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "2025-07-06 11:17:37,362 - src.vision_parser.parser - WARNING - Warning: Error processing page 2: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "2025-07-06 11:17:37,362 - src.vision_parser.parser - INFO - Processing page 3/4\n",
      "2025-07-06 11:17:59,015 - src.vision_parser.parser - ERROR - Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "2025-07-06 11:17:59,015 - src.vision_parser.parser - WARNING - Warning: Error processing page 3: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "2025-07-06 11:17:59,015 - src.vision_parser.parser - INFO - Processing page 4/4\n",
      "2025-07-06 11:18:20,404 - src.vision_parser.parser - ERROR - Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "2025-07-06 11:18:20,406 - src.vision_parser.parser - WARNING - Warning: Error processing page 4: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "Conversion failed:\n",
      "  - Error processing page 1: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "  - Error processing page 2: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "  - Error processing page 3: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "  - Error processing page 4: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "âŒ Conversion failed:\n",
      "   - Error processing page 1: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "   - Error processing page 2: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "   - Error processing page 3: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "   - Error processing page 4: Vision processing failed: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "PDF_PATH = \"sample_document.pdf\"\n",
    "OLLAMA_MODEL = \"qwen2.5vl:3b-q4_K_M\"  # Or any vision model you have\n",
    "OLLAMA_BASE_URL = \"http://192.168.100.80:1818\"\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "print(\"=== Simple Vision-Only PDF Conversion ===\")\n",
    "\n",
    "# Method 1: Simple one-liner\n",
    "result = convert_pdf_to_markdown_simple(\n",
    "    pdf_path=PDF_PATH,\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    dpi=300,  # Higher DPI for better quality\n",
    "    log_level=\"INFO\"\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(f\"Successfully converted {len(result.pages)} pages\")\n",
    "    print(f\"Output saved to: {OUTPUT_DIR}\")\n",
    "    \n",
    "    # Show first page preview\n",
    "    if result.pages:\n",
    "        first_page = result.pages[0]\n",
    "        print(f\"\\nFirst page preview ({len(first_page)} characters):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(first_page[:500] + \"...\" if len(first_page) > 500 else first_page)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of using the pipeline directly for more control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = SimplePDFToMarkdownPipeline(\n",
    "    ollama_model=\"qwen2.5vl:3b-q4_K_M\",\n",
    "    ollama_base_url=\"http://192.168.100.80:1818\",\n",
    "    dpi=400  # Higher resolution\n",
    ")\n",
    "\n",
    "# Convert PDF\n",
    "result = pipeline.convert_pdf(\"sample_document.pdf\")\n",
    "\n",
    "if result.success:\n",
    "    # Process each page individually\n",
    "    for i, page_content in enumerate(result.pages):\n",
    "        print(f\"\\nPage {i+1} ({len(page_content)} characters)\")\n",
    "        \n",
    "        # TODO add custom post-processing here\n",
    "    \n",
    "    # Save with custom directory\n",
    "    saved_files = pipeline.save_results(result, \"./custom_output\")\n",
    "    print(f\"Saved {len(saved_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Vision-Only PDF Conversion ===\n"
     ]
    }
   ],
   "source": [
    "# Import the pipeline components\n",
    "import sys\n",
    "import fitz\n",
    "sys.path.append('.')  # Adjust path as needed\n",
    "\n",
    "from src.hybrid_parser.pipeline import (\n",
    "    PDFToMarkdownPipeline, \n",
    "    PipelineConfig,\n",
    "    convert_pdf_to_markdown\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: qwen2.5vl:3b-q4_K_M\n",
      "Ollama server: http://192.168.100.80:1818\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "OLLAMA_MODEL = \"qwen2.5vl:3b-q4_K_M\"  # Change to your preferred model\n",
    "OLLAMA_BASE_URL = \"http://192.168.100.80:1818\"  # Your Ollama server URL\n",
    "PDF_PATH = \"sample_document.pdf\"  # Path to your PDF file\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Using model: {OLLAMA_MODEL}\")\n",
    "print(f\"Ollama server: {OLLAMA_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Simple conversion (output is saved in a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Conversion ===\n",
      "2025-07-05 14:47:36,901 - src.vision_processor - INFO - Connected to Ollama at http://192.168.100.80:1818\n",
      "2025-07-05 14:47:36,904 - src.vision_processor - INFO - VisionProcessor initialized with model: qwen2.5vl:3b-q4_K_M\n",
      "2025-07-05 14:47:36,906 - src.markdown_generator - DEBUG - MarkdownGenerator initialized with config: {'dpi': 300, 'vision_model_temp': 0.1, 'text_extraction_priority': True, 'image_embed_mode': 'base64', 'preserve_formatting': True, 'table_detection_threshold': 0.7, 'formula_detection_threshold': 0.8, 'min_image_size': (50, 50)}\n",
      "2025-07-05 14:47:36,914 - src.pipeline - INFO - Processing PDF with 4 pages...\n",
      "2025-07-05 14:47:36,922 - src.pipeline - INFO - Processing page 1/4\n",
      "2025-07-05 14:47:36,923 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:47:36,936 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:47:36,941 - src.pdf_analyzer - DEBUG - Text_coverage:0.1297491770806737\n",
      "2025-07-05 14:47:37,006 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:47:37,010 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:47:37,014 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:47:37,023 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.60)\n",
      "2025-07-05 14:47:37,025 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 14:47:37,032 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:47:37,502 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:47:37,507 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:47:37,509 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 148342\n",
      "2025-07-05 14:47:37,933 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:47:37,938 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:47:37,940 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:47:37,974 - httpcore.connection - DEBUG - connect_tcp.started host='192.168.100.80' port=1818 local_address=None timeout=None socket_options=None\n",
      "2025-07-05 14:47:37,986 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016624E5D850>\n",
      "2025-07-05 14:47:37,990 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:37,994 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:47:37,996 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:37,998 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:47:38,001 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:47,305 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:47:47 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:47:47,307 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,040 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:47:55,042 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:47:55,044 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:47:55,045 - src.vision_processor - DEBUG - Vision model response received, length: 773\n",
      "2025-07-05 14:47:55,047 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:47:55,053 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:47:55,056 - src.pipeline - INFO - Processing page 2/4\n",
      "2025-07-05 14:47:55,059 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:47:55,067 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:47:55,072 - src.pdf_analyzer - DEBUG - Text_coverage:0.14366892052793828\n",
      "2025-07-05 14:47:55,076 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:47:55,080 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:47:55,085 - src.pdf_analyzer - DEBUG - Has formulas:True\n",
      "2025-07-05 14:47:55,094 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.70)\n",
      "2025-07-05 14:47:55,097 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 14:47:55,108 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:47:55,431 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:47:55,434 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:47:55,437 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 154081\n",
      "2025-07-05 14:47:55,812 - src.pipeline - INFO -     Extracting formulas...\n",
      "2025-07-05 14:47:55,814 - src.vision_processor - DEBUG - Extracting formulas from image\n",
      "2025-07-05 14:47:55,815 - src.vision_processor - DEBUG - Processing image content with type: formula\n",
      "2025-07-05 14:47:55,828 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,830 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:47:55,832 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,837 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:47:55,841 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:02,800 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:02 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:02,804 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,908 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:03,911 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:03,913 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:03,916 - src.vision_processor - DEBUG - Vision model response received, length: 53\n",
      "2025-07-05 14:48:03,918 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:03,920 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:03,921 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:03,937 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,939 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:03,942 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,946 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:03,948 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:04,512 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:04 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:04,515 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:28,311 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:28,313 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:28,314 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:28,316 - src.vision_processor - DEBUG - Vision model response received, length: 2058\n",
      "2025-07-05 14:48:28,317 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:48:28,327 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:48:28,328 - src.pipeline - INFO - Processing page 3/4\n",
      "2025-07-05 14:48:28,329 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:48:28,332 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:48:28,336 - src.pdf_analyzer - DEBUG - Text_coverage:0.06992337224219923\n",
      "2025-07-05 14:48:28,339 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:48:28,341 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:48:28,343 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:48:28,346 - src.pipeline - INFO -   Strategy: vision_only (confidence: 0.80)\n",
      "2025-07-05 14:48:28,347 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:48:28,811 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:48:28,812 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:48:28,814 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 4472495\n",
      "2025-07-05 14:48:29,082 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:29,084 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:29,086 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:29,108 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:29,110 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:29,111 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:29,112 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:29,113 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:36,219 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:36 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:36,221 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:43,884 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:43,886 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:43,889 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:43,891 - src.vision_processor - DEBUG - Vision model response received, length: 1056\n",
      "2025-07-05 14:48:43,892 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:48:43,894 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:48:43,896 - src.pipeline - INFO - Processing page 4/4\n",
      "2025-07-05 14:48:43,897 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:48:43,902 - src.pdf_analyzer - DEBUG - Has text:False\n",
      "2025-07-05 14:48:43,906 - src.pdf_analyzer - DEBUG - Text_coverage:0.0\n",
      "2025-07-05 14:48:43,908 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:48:43,910 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:48:43,913 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:48:43,917 - src.pipeline - INFO -   Strategy: vision_only (confidence: 0.80)\n",
      "2025-07-05 14:48:43,918 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:48:44,447 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:48:44,450 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:48:44,452 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 188735\n",
      "2025-07-05 14:48:44,696 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:44,698 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:44,701 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:44,711 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:44,712 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:44,714 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:44,718 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:44,721 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:51,701 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:51 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:51,702 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:49:14,519 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:49:14,520 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:49:14,521 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:49:14,522 - src.vision_processor - DEBUG - Vision model response received, length: 2855\n",
      "2025-07-05 14:49:14,523 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:49:14,523 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:49:14,525 - src.pipeline - INFO - Saving results to ./output\n",
      "2025-07-05 14:49:14,529 - src.pipeline - DEBUG - Saved page 1 to output\\page_001.md\n",
      "2025-07-05 14:49:14,532 - src.pipeline - DEBUG - Saved page 2 to output\\page_002.md\n",
      "2025-07-05 14:49:14,536 - src.pipeline - DEBUG - Saved page 3 to output\\page_003.md\n",
      "2025-07-05 14:49:14,539 - src.pipeline - DEBUG - Saved page 4 to output\\page_004.md\n",
      "2025-07-05 14:49:14,541 - src.pipeline - DEBUG - Saved combined document to output\\combined_document.md\n",
      "2025-07-05 14:49:14,543 - src.pipeline - DEBUG - Saved metadata to output\\conversion_metadata.json\n",
      "2025-07-05 14:49:14,546 - src.pipeline - INFO - Successfully saved 6 files to ./output\n",
      "Conversion completed! Files saved to ./output\n",
      "  - output\\page_001.md\n",
      "  - output\\page_002.md\n",
      "  - output\\page_003.md\n",
      "  - output\\page_004.md\n",
      "  - output\\combined_document.md\n",
      "  - output\\conversion_metadata.json\n",
      "âœ… Successfully converted 4 pages\n",
      "ðŸ“ Output saved to: ./output\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Simple Conversion ===\")\n",
    "\n",
    "result = convert_pdf_to_markdown(\n",
    "    pdf_path=PDF_PATH,\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    log_level=\"DEBUG\"\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(f\"âœ… Successfully converted {len(result.pages)} pages\")\n",
    "    print(f\"ðŸ“ Output saved to: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"âŒ Conversion failed:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"   - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Advanced usage with custom configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Advanced Configuration ===\n",
      "Pipeline Configuration:\n",
      "  analyzer: PDFAnalyzer\n",
      "  text_extractor: TextExtractor\n",
      "  vision_processor: VisionProcessor\n",
      "  integrator: ContentIntegrator\n",
      "  markdown_generator: MarkdownGenerator\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Advanced Configuration ===\")\n",
    "\n",
    "# Create custom configuration\n",
    "config = PipelineConfig()\n",
    "config.dpi = 400  # Higher resolution for better OCR\n",
    "config.vision_model_temp = 0.1  # Lower temperature for consistent output\n",
    "config.text_extraction_priority = True  # Prefer text extraction when possible\n",
    "config.preserve_formatting = True  # Maintain original formatting\n",
    "config.image_embed_mode = \"base64\"  # Embed images as base64\n",
    "\n",
    "# Initialize pipeline with custom config\n",
    "pipeline = PDFToMarkdownPipeline(\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Show pipeline information\n",
    "print(\"Pipeline Configuration:\")\n",
    "info = pipeline.get_pipeline_info()\n",
    "for component, name in info[\"components\"].items():\n",
    "    print(f\"  {component}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Process single page for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Page Processing ===\n",
      "Analyzing first page...\n",
      "Page Analysis:\n",
      "  - Has extractable text: True\n",
      "  - Text coverage: 0.12\n",
      "  - Has images: False\n",
      "  - Has tables: False\n",
      "  - Has formulas: False\n",
      "  - Layout complexity: 0.90\n",
      "  - Recommended strategy: vision_only\n",
      "  - Confidence: 0.80\n",
      "\n",
      "Processing page...\n",
      "  Analyzing page structure...\n",
      "  Strategy: vision_only (confidence: 0.80)\n",
      "  Processing with vision model...\n",
      "    General content extraction...\n",
      "  Integrating content...\n",
      "  Generating markdown...\n",
      "\n",
      "Generated markdown (0 characters):\n",
      "==================================================\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Single Page Processing ===\")\n",
    "\n",
    "import fitz\n",
    "\n",
    "# Open PDF and process first page only\n",
    "with  fitz.open(PDF_PATH) as doc:\n",
    "    if doc.page_count > 0:\n",
    "        first_page = doc[0]\n",
    "        \n",
    "        print(\"Analyzing first page...\")\n",
    "        analysis = pipeline.analyzer.analyze_page_content(first_page)\n",
    "        \n",
    "        print(f\"Page Analysis:\")\n",
    "        print(f\"  - Has extractable text: {analysis.has_extractable_text}\")\n",
    "        print(f\"  - Text coverage: {analysis.text_coverage:.2f}\")\n",
    "        print(f\"  - Has images: {analysis.has_images}\")\n",
    "        print(f\"  - Has tables: {analysis.has_tables}\")\n",
    "        print(f\"  - Has formulas: {analysis.has_formulas}\")\n",
    "        print(f\"  - Recommended strategy: {analysis.strategy.value}\")\n",
    "        print(f\"  - Confidence: {analysis.confidence:.2f}\")\n",
    "        \n",
    "        # Process the page\n",
    "        print(\"\\nProcessing page...\")\n",
    "        page_markdown = pipeline.convert_page(first_page)\n",
    "        \n",
    "        print(f\"\\nGenerated markdown ({len(page_markdown)} characters):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(page_markdown[:500] + \"...\" if len(page_markdown) > 500 else page_markdown)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Batch processing with custom content handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch Processing with Content Analysis ===\n",
      "Analyzing PDF structure (1 pages)...\n",
      "Page 1: vision_only (conf: 0.80, complex: 0.90)\n",
      "\n",
      "Strategy Distribution:\n",
      "  vision_only: 1 pages\n",
      "\n",
      "Average layout complexity: 0.90\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Batch Processing with Content Analysis ===\")\n",
    "\n",
    "def analyze_pdf_structure(pdf_path: str):\n",
    "    \"\"\"Analyze entire PDF structure before processing\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        analyses = {}\n",
    "        \n",
    "        print(f\"Analyzing PDF structure ({doc.page_count} pages)...\")\n",
    "        \n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc[page_num]\n",
    "            analysis = pipeline.analyzer.analyze_page_content(page)\n",
    "            analyses[page_num] = analysis\n",
    "            \n",
    "            print(f\"Page {page_num + 1}: {analysis.strategy.value} \"\n",
    "                f\"(conf: {analysis.confidence:.2f}, \")\n",
    "    \n",
    "    return analyses\n",
    "\n",
    "# Analyze structure first\n",
    "if Path(PDF_PATH).exists():\n",
    "    pdf_analyses = analyze_pdf_structure(PDF_PATH)\n",
    "    \n",
    "    # Show summary statistics\n",
    "    strategies = [a.strategy.value for a in pdf_analyses.values()]\n",
    "    strategy_counts = {s: strategies.count(s) for s in set(strategies)}\n",
    "    \n",
    "    print(\"\\nStrategy Distribution:\")\n",
    "    for strategy, count in strategy_counts.items():\n",
    "        print(f\"  {strategy}: {count} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Testing different vision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Model Comparison ===\")\n",
    "\n",
    "# List of models to test (uncomment available models)\n",
    "test_models = [\n",
    "    \"llama3.2-vision:11b\",\n",
    "    \"qwen2.5vl:3b-q4_K_M\",\n",
    "    # \"llava:13b\",\n",
    "    # \"bakllava\",\n",
    "]\n",
    "\n",
    "def test_model_performance(models: list, test_pdf: str):\n",
    "    \"\"\"Test different models on the same page\"\"\"\n",
    "    if not Path(test_pdf).exists():\n",
    "        print(f\"Test PDF not found: {test_pdf}\")\n",
    "        return\n",
    "    \n",
    "    with fitz.open(test_pdf) as doc:\n",
    "        test_page = doc[0]  # Use first page for testing\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for model in models:\n",
    "            try:\n",
    "                print(f\"\\nTesting model: {model}\")\n",
    "                \n",
    "                # Create pipeline with this model\n",
    "                test_pipeline = PDFToMarkdownPipeline(model, OLLAMA_BASE_URL)\n",
    "                \n",
    "                # Process page\n",
    "                markdown = test_pipeline.convert_page(test_page)\n",
    "                \n",
    "                results[model] = {\n",
    "                    \"success\": True,\n",
    "                    \"length\": len(markdown),\n",
    "                    \"preview\": markdown[:200] + \"...\" if len(markdown) > 200 else markdown\n",
    "                }\n",
    "                \n",
    "                print(f\"  âœ… Success - {len(markdown)} chars\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[model] = {\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "                print(f\"  âŒ Failed: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run model comparison (only if you have multiple models)\n",
    "if len(test_models) > 1:\n",
    "    model_results = test_model_performance(test_models, PDF_PATH)\n",
    "    \n",
    "    print(\"\\n=== Model Comparison Results ===\")\n",
    "    for model, result in model_results.items():\n",
    "        if result[\"success\"]:\n",
    "            print(f\"{model}: {result['length']} characters\")\n",
    "        else:\n",
    "            print(f\"{model}: FAILED - {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Error handling and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/fberge/OneDrive - Studiecentrum voor Kernenergie/Documents/python/vision-parse/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Error Handling Examples ===\")\n",
    "\n",
    "# Test with non-existent file\n",
    "print(\"Testing with non-existent file...\")\n",
    "bad_result = convert_pdf_to_markdown(\"nonexistent.pdf\", OLLAMA_MODEL, OLLAMA_BASE_URL)\n",
    "print(f\"Expected failure: {not bad_result.success}\")\n",
    "\n",
    "# Test with wrong Ollama URL\n",
    "print(\"\\nTesting with wrong Ollama URL...\")\n",
    "try:\n",
    "    bad_pipeline = PDFToMarkdownPipeline(OLLAMA_MODEL, \"http://localhost:99999\")\n",
    "    # This will fail when we try to use the vision processor\n",
    "    print(\"Pipeline created (will fail on actual processing)\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "\n",
    "# %%\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PDF to Markdown Pipeline Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Path(OUTPUT_DIR).exists():\n",
    "    output_files = list(Path(OUTPUT_DIR).glob(\"*\"))\n",
    "    print(f\"\\nGenerated files in {OUTPUT_DIR}:\")\n",
    "    for file in output_files:\n",
    "        size = file.stat().st_size if file.is_file() else 0\n",
    "        print(f\"  ðŸ“„ {file.name} ({size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nPipeline ready for production use!\")\n",
    "print(f\"ðŸ’¡ Tip: Adjust PipelineConfig settings for your specific needs\")\n",
    "print(f\"ðŸ”§ Remember to tune vision model temperature and DPI settings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
