{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF to Markdown Pipeline - Usage Example Notebook\n",
    "================================================\n",
    "\n",
    "This notebook demonstrates how to use the high-fidelity PDF to Markdown pipeline\n",
    "with LangChain Ollama integration.\n",
    "\n",
    "Prerequisites:\n",
    "- Ollama server running with a vision model (e.g., llama3.2-vision:11b)\n",
    "- Required Python packages: PyMuPDF, langchain-ollama, PIL, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-ollama) (0.5.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.60 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-ollama) (0.3.68)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (4.14.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.11.7)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from ollama<1.0.0,>=0.4.8->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\fberge\\documents\\python\\ollama-pdf-parser\\.venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simple_vision_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Install required packages (run once)\u001b[39;00m\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall pymupdf langchain-ollama pillow\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msimple_vision_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_pdf_to_markdown_simple, SimplePDFToMarkdownPipeline\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'simple_vision_pipeline'"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install pymupdf langchain-ollama pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple pipeline (vision only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vision_parser.parser import convert_pdf_to_markdown, PDFToMarkdownPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Vision-Only PDF Conversion ===\n",
      "2025-07-07 12:12:49,916 - src.vision_parser.parser - INFO - Connected to Ollama at http://127.0.0.1:11434\n",
      "2025-07-07 12:12:49,919 - src.vision_parser.parser - INFO - VisionProcessor initialized with model: qwen2.5vl:3b-q4_K_M\n",
      "2025-07-07 12:12:49,922 - src.vision_parser.parser - INFO - Text validation enabled with threshold: 0.65\n",
      "2025-07-07 12:12:49,925 - src.vision_parser.parser - INFO - Processing PDF with 4 pages...\n",
      "2025-07-07 12:12:49,925 - src.vision_parser.parser - INFO - Processing page 1/4\n",
      "2025-07-07 12:18:24,955 - src.vision_parser.parser - INFO - Processing page 2/4\n",
      "2025-07-07 12:23:49,168 - src.vision_parser.parser - INFO - Processing page 3/4\n",
      "2025-07-07 12:28:41,672 - src.vision_parser.parser - INFO - Processing page 4/4\n",
      "2025-07-07 12:33:08,641 - src.vision_parser.parser - INFO - Running text validation...\n",
      "2025-07-07 12:33:08,737 - src.vision_parser.validation - INFO - Text validation ✅ PASSED (score: 0.895)\n",
      "2025-07-07 12:33:08,745 - src.vision_parser.validation - INFO - Text validation ❌ FAILED (score: 0.649)\n",
      "2025-07-07 12:33:08,745 - src.vision_parser.validation - INFO - Text validation ✅ PASSED (score: 0.941)\n",
      "2025-07-07 12:33:08,745 - src.vision_parser.validation - INFO - Text validation ❌ FAILED (score: 0.000)\n",
      "2025-07-07 12:33:08,745 - src.vision_parser.validation - INFO - Document validation: 2/4 pages passed (avg score: 0.621)\n",
      "2025-07-07 12:33:08,745 - src.vision_parser.parser - INFO - Validation complete: 2/4 pages passed (avg score: 0.621)\n",
      "2025-07-07 12:33:08,745 - src.vision_parser.parser - INFO - Saving results to ./output\n",
      "2025-07-07 12:33:08,762 - src.vision_parser.parser - INFO - Successfully saved 7 files to ./output\n",
      "Conversion completed! Files saved to ./output\n",
      "  - output\\page_001.md\n",
      "  - output\\page_002.md\n",
      "  - output\\page_003.md\n",
      "  - output\\page_004.md\n",
      "  - output\\combined_document.md\n",
      "  - output\\conversion_metadata.json\n",
      "  - output\\validation_report.json\n",
      "\n",
      "Validation Summary:\n",
      "  ✅ Passed: 2/4 pages\n",
      "  📊 Average score: 0.621\n",
      "  ⚠️  Failed pages: [2, 4]\n",
      "Successfully converted 4 pages\n",
      "Output saved to: ./output\n",
      "\n",
      "First page preview (746 characters):\n",
      "==================================================\n",
      "1 Introduction\n",
      "Les marchés locaux jouent un rôle essentiel dans l'économie de proximité. Ils permettent aux producteurs de vendre directement aux consommateurs, favorisant ainsi les circuits courts et la fraîcheur des produits. Cette étude propose une analyse simplifiée des dynamiques commerciales observées.\n",
      "\n",
      "1.1 Contexte\n",
      "Depuis plusieurs années, l'intérêt pour les produits locaux ne cesse de croître. Les consommateurs recherchent davantage de transparence et de qualité. Cette évolution influenc...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "PDF_PATH = \"sample_document.pdf\"\n",
    "OLLAMA_MODEL = \"qwen2.5vl:3b-q4_K_M\"  # Or any vision model you have\n",
    "OLLAMA_BASE_URL = \"http://127.0.0.1:11434\"  #\"http://192.168.100.80:1818\"\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "print(\"=== Simple Vision-Only PDF Conversion ===\")\n",
    "\n",
    "# Method 1: Simple one-liner\n",
    "result = convert_pdf_to_markdown(\n",
    "    pdf_path=PDF_PATH,\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    dpi=300,  # Higher DPI for better quality\n",
    "    log_level=\"INFO\"\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(f\"Successfully converted {len(result.pages)} pages\")\n",
    "    print(f\"Output saved to: {OUTPUT_DIR}\")\n",
    "    \n",
    "    # Show first page preview\n",
    "    if result.pages:\n",
    "        first_page = result.pages[0]\n",
    "        print(f\"\\nFirst page preview ({len(first_page)} characters):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(first_page[:500] + \"...\" if len(first_page) > 500 else first_page)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of using the pipeline directly for more control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = PDFToMarkdownPipeline(\n",
    "    ollama_model=\"qwen2.5vl:3b-q4_K_M\",\n",
    "    ollama_base_url=\"http://192.168.100.80:1818\",\n",
    "    enable_validation=False\n",
    "    dpi=400  # Higher resolution\n",
    ")\n",
    "\n",
    "# Convert PDF\n",
    "result = pipeline.convert_pdf(\"sample_document.pdf\")\n",
    "\n",
    "if result.success:\n",
    "    # Process each page individually\n",
    "    for i, page_content in enumerate(result.pages):\n",
    "        print(f\"\\nPage {i+1} ({len(page_content)} characters)\")\n",
    "    \n",
    "    # Save with custom directory\n",
    "    saved_files = pipeline.save_results(result, \"./custom_output\")\n",
    "    print(f\"Saved {len(saved_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Vision-Only PDF Conversion ===\n"
     ]
    }
   ],
   "source": [
    "# Import the pipeline components\n",
    "import sys\n",
    "import fitz\n",
    "sys.path.append('.')  # Adjust path as needed\n",
    "\n",
    "from src.hybrid_parser.pipeline import (\n",
    "    PDFToMarkdownPipeline, \n",
    "    PipelineConfig,\n",
    "    convert_pdf_to_markdown\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: qwen2.5vl:3b-q4_K_M\n",
      "Ollama server: http://192.168.100.80:1818\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "OLLAMA_MODEL = \"qwen2.5vl:3b-q4_K_M\"  # Change to your preferred model\n",
    "OLLAMA_BASE_URL = \"http://192.168.100.80:1818\"  # Your Ollama server URL\n",
    "PDF_PATH = \"sample_document.pdf\"  # Path to your PDF file\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Using model: {OLLAMA_MODEL}\")\n",
    "print(f\"Ollama server: {OLLAMA_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Simple conversion (output is saved in a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Conversion ===\n",
      "2025-07-05 14:47:36,901 - src.vision_processor - INFO - Connected to Ollama at http://192.168.100.80:1818\n",
      "2025-07-05 14:47:36,904 - src.vision_processor - INFO - VisionProcessor initialized with model: qwen2.5vl:3b-q4_K_M\n",
      "2025-07-05 14:47:36,906 - src.markdown_generator - DEBUG - MarkdownGenerator initialized with config: {'dpi': 300, 'vision_model_temp': 0.1, 'text_extraction_priority': True, 'image_embed_mode': 'base64', 'preserve_formatting': True, 'table_detection_threshold': 0.7, 'formula_detection_threshold': 0.8, 'min_image_size': (50, 50)}\n",
      "2025-07-05 14:47:36,914 - src.pipeline - INFO - Processing PDF with 4 pages...\n",
      "2025-07-05 14:47:36,922 - src.pipeline - INFO - Processing page 1/4\n",
      "2025-07-05 14:47:36,923 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:47:36,936 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:47:36,941 - src.pdf_analyzer - DEBUG - Text_coverage:0.1297491770806737\n",
      "2025-07-05 14:47:37,006 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:47:37,010 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:47:37,014 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:47:37,023 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.60)\n",
      "2025-07-05 14:47:37,025 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 14:47:37,032 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:47:37,502 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:47:37,507 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:47:37,509 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 148342\n",
      "2025-07-05 14:47:37,933 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:47:37,938 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:47:37,940 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:47:37,974 - httpcore.connection - DEBUG - connect_tcp.started host='192.168.100.80' port=1818 local_address=None timeout=None socket_options=None\n",
      "2025-07-05 14:47:37,986 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016624E5D850>\n",
      "2025-07-05 14:47:37,990 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:37,994 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:47:37,996 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:37,998 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:47:38,001 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:47,305 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:47:47 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:47:47,307 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,040 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:47:55,042 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:47:55,044 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:47:55,045 - src.vision_processor - DEBUG - Vision model response received, length: 773\n",
      "2025-07-05 14:47:55,047 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:47:55,053 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:47:55,056 - src.pipeline - INFO - Processing page 2/4\n",
      "2025-07-05 14:47:55,059 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:47:55,067 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:47:55,072 - src.pdf_analyzer - DEBUG - Text_coverage:0.14366892052793828\n",
      "2025-07-05 14:47:55,076 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:47:55,080 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:47:55,085 - src.pdf_analyzer - DEBUG - Has formulas:True\n",
      "2025-07-05 14:47:55,094 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.70)\n",
      "2025-07-05 14:47:55,097 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 14:47:55,108 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:47:55,431 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:47:55,434 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:47:55,437 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 154081\n",
      "2025-07-05 14:47:55,812 - src.pipeline - INFO -     Extracting formulas...\n",
      "2025-07-05 14:47:55,814 - src.vision_processor - DEBUG - Extracting formulas from image\n",
      "2025-07-05 14:47:55,815 - src.vision_processor - DEBUG - Processing image content with type: formula\n",
      "2025-07-05 14:47:55,828 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,830 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:47:55,832 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,837 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:47:55,841 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:02,800 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:02 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:02,804 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,908 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:03,911 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:03,913 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:03,916 - src.vision_processor - DEBUG - Vision model response received, length: 53\n",
      "2025-07-05 14:48:03,918 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:03,920 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:03,921 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:03,937 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,939 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:03,942 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,946 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:03,948 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:04,512 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:04 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:04,515 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:28,311 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:28,313 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:28,314 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:28,316 - src.vision_processor - DEBUG - Vision model response received, length: 2058\n",
      "2025-07-05 14:48:28,317 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:48:28,327 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:48:28,328 - src.pipeline - INFO - Processing page 3/4\n",
      "2025-07-05 14:48:28,329 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:48:28,332 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:48:28,336 - src.pdf_analyzer - DEBUG - Text_coverage:0.06992337224219923\n",
      "2025-07-05 14:48:28,339 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:48:28,341 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:48:28,343 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:48:28,346 - src.pipeline - INFO -   Strategy: vision_only (confidence: 0.80)\n",
      "2025-07-05 14:48:28,347 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:48:28,811 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:48:28,812 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:48:28,814 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 4472495\n",
      "2025-07-05 14:48:29,082 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:29,084 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:29,086 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:29,108 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:29,110 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:29,111 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:29,112 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:29,113 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:36,219 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:36 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:36,221 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:43,884 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:43,886 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:43,889 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:43,891 - src.vision_processor - DEBUG - Vision model response received, length: 1056\n",
      "2025-07-05 14:48:43,892 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:48:43,894 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:48:43,896 - src.pipeline - INFO - Processing page 4/4\n",
      "2025-07-05 14:48:43,897 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:48:43,902 - src.pdf_analyzer - DEBUG - Has text:False\n",
      "2025-07-05 14:48:43,906 - src.pdf_analyzer - DEBUG - Text_coverage:0.0\n",
      "2025-07-05 14:48:43,908 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:48:43,910 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:48:43,913 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:48:43,917 - src.pipeline - INFO -   Strategy: vision_only (confidence: 0.80)\n",
      "2025-07-05 14:48:43,918 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:48:44,447 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:48:44,450 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:48:44,452 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 188735\n",
      "2025-07-05 14:48:44,696 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:44,698 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:44,701 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:44,711 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:44,712 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:44,714 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:44,718 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:44,721 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:51,701 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:51 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:51,702 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:49:14,519 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:49:14,520 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:49:14,521 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:49:14,522 - src.vision_processor - DEBUG - Vision model response received, length: 2855\n",
      "2025-07-05 14:49:14,523 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:49:14,523 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:49:14,525 - src.pipeline - INFO - Saving results to ./output\n",
      "2025-07-05 14:49:14,529 - src.pipeline - DEBUG - Saved page 1 to output\\page_001.md\n",
      "2025-07-05 14:49:14,532 - src.pipeline - DEBUG - Saved page 2 to output\\page_002.md\n",
      "2025-07-05 14:49:14,536 - src.pipeline - DEBUG - Saved page 3 to output\\page_003.md\n",
      "2025-07-05 14:49:14,539 - src.pipeline - DEBUG - Saved page 4 to output\\page_004.md\n",
      "2025-07-05 14:49:14,541 - src.pipeline - DEBUG - Saved combined document to output\\combined_document.md\n",
      "2025-07-05 14:49:14,543 - src.pipeline - DEBUG - Saved metadata to output\\conversion_metadata.json\n",
      "2025-07-05 14:49:14,546 - src.pipeline - INFO - Successfully saved 6 files to ./output\n",
      "Conversion completed! Files saved to ./output\n",
      "  - output\\page_001.md\n",
      "  - output\\page_002.md\n",
      "  - output\\page_003.md\n",
      "  - output\\page_004.md\n",
      "  - output\\combined_document.md\n",
      "  - output\\conversion_metadata.json\n",
      "✅ Successfully converted 4 pages\n",
      "📁 Output saved to: ./output\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Simple Conversion ===\")\n",
    "\n",
    "result = convert_pdf_to_markdown(\n",
    "    pdf_path=PDF_PATH,\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    log_level=\"DEBUG\"\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(f\"✅ Successfully converted {len(result.pages)} pages\")\n",
    "    print(f\"📁 Output saved to: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"❌ Conversion failed:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"   - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Advanced usage with custom configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Advanced Configuration ===\n",
      "Pipeline Configuration:\n",
      "  analyzer: PDFAnalyzer\n",
      "  text_extractor: TextExtractor\n",
      "  vision_processor: VisionProcessor\n",
      "  integrator: ContentIntegrator\n",
      "  markdown_generator: MarkdownGenerator\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Advanced Configuration ===\")\n",
    "\n",
    "# Create custom configuration\n",
    "config = PipelineConfig()\n",
    "config.dpi = 400  # Higher resolution for better OCR\n",
    "config.vision_model_temp = 0.1  # Lower temperature for consistent output\n",
    "config.text_extraction_priority = True  # Prefer text extraction when possible\n",
    "config.preserve_formatting = True  # Maintain original formatting\n",
    "config.image_embed_mode = \"base64\"  # Embed images as base64\n",
    "\n",
    "# Initialize pipeline with custom config\n",
    "pipeline = PDFToMarkdownPipeline(\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Show pipeline information\n",
    "print(\"Pipeline Configuration:\")\n",
    "info = pipeline.get_pipeline_info()\n",
    "for component, name in info[\"components\"].items():\n",
    "    print(f\"  {component}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Process single page for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Page Processing ===\n",
      "Analyzing first page...\n",
      "Page Analysis:\n",
      "  - Has extractable text: True\n",
      "  - Text coverage: 0.12\n",
      "  - Has images: False\n",
      "  - Has tables: False\n",
      "  - Has formulas: False\n",
      "  - Layout complexity: 0.90\n",
      "  - Recommended strategy: vision_only\n",
      "  - Confidence: 0.80\n",
      "\n",
      "Processing page...\n",
      "  Analyzing page structure...\n",
      "  Strategy: vision_only (confidence: 0.80)\n",
      "  Processing with vision model...\n",
      "    General content extraction...\n",
      "  Integrating content...\n",
      "  Generating markdown...\n",
      "\n",
      "Generated markdown (0 characters):\n",
      "==================================================\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Single Page Processing ===\")\n",
    "\n",
    "import fitz\n",
    "\n",
    "# Open PDF and process first page only\n",
    "with  fitz.open(PDF_PATH) as doc:\n",
    "    if doc.page_count > 0:\n",
    "        first_page = doc[0]\n",
    "        \n",
    "        print(\"Analyzing first page...\")\n",
    "        analysis = pipeline.analyzer.analyze_page_content(first_page)\n",
    "        \n",
    "        print(f\"Page Analysis:\")\n",
    "        print(f\"  - Has extractable text: {analysis.has_extractable_text}\")\n",
    "        print(f\"  - Text coverage: {analysis.text_coverage:.2f}\")\n",
    "        print(f\"  - Has images: {analysis.has_images}\")\n",
    "        print(f\"  - Has tables: {analysis.has_tables}\")\n",
    "        print(f\"  - Has formulas: {analysis.has_formulas}\")\n",
    "        print(f\"  - Recommended strategy: {analysis.strategy.value}\")\n",
    "        print(f\"  - Confidence: {analysis.confidence:.2f}\")\n",
    "        \n",
    "        # Process the page\n",
    "        print(\"\\nProcessing page...\")\n",
    "        page_markdown = pipeline.convert_page(first_page)\n",
    "        \n",
    "        print(f\"\\nGenerated markdown ({len(page_markdown)} characters):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(page_markdown[:500] + \"...\" if len(page_markdown) > 500 else page_markdown)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Batch processing with custom content handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch Processing with Content Analysis ===\n",
      "Analyzing PDF structure (1 pages)...\n",
      "Page 1: vision_only (conf: 0.80, complex: 0.90)\n",
      "\n",
      "Strategy Distribution:\n",
      "  vision_only: 1 pages\n",
      "\n",
      "Average layout complexity: 0.90\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Batch Processing with Content Analysis ===\")\n",
    "\n",
    "def analyze_pdf_structure(pdf_path: str):\n",
    "    \"\"\"Analyze entire PDF structure before processing\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        analyses = {}\n",
    "        \n",
    "        print(f\"Analyzing PDF structure ({doc.page_count} pages)...\")\n",
    "        \n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc[page_num]\n",
    "            analysis = pipeline.analyzer.analyze_page_content(page)\n",
    "            analyses[page_num] = analysis\n",
    "            \n",
    "            print(f\"Page {page_num + 1}: {analysis.strategy.value} \"\n",
    "                f\"(conf: {analysis.confidence:.2f}, \")\n",
    "    \n",
    "    return analyses\n",
    "\n",
    "# Analyze structure first\n",
    "if Path(PDF_PATH).exists():\n",
    "    pdf_analyses = analyze_pdf_structure(PDF_PATH)\n",
    "    \n",
    "    # Show summary statistics\n",
    "    strategies = [a.strategy.value for a in pdf_analyses.values()]\n",
    "    strategy_counts = {s: strategies.count(s) for s in set(strategies)}\n",
    "    \n",
    "    print(\"\\nStrategy Distribution:\")\n",
    "    for strategy, count in strategy_counts.items():\n",
    "        print(f\"  {strategy}: {count} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Testing different vision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Model Comparison ===\")\n",
    "\n",
    "# List of models to test (uncomment available models)\n",
    "test_models = [\n",
    "    \"llama3.2-vision:11b\",\n",
    "    \"qwen2.5vl:3b-q4_K_M\",\n",
    "    # \"llava:13b\",\n",
    "    # \"bakllava\",\n",
    "]\n",
    "\n",
    "def test_model_performance(models: list, test_pdf: str):\n",
    "    \"\"\"Test different models on the same page\"\"\"\n",
    "    if not Path(test_pdf).exists():\n",
    "        print(f\"Test PDF not found: {test_pdf}\")\n",
    "        return\n",
    "    \n",
    "    with fitz.open(test_pdf) as doc:\n",
    "        test_page = doc[0]  # Use first page for testing\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for model in models:\n",
    "            try:\n",
    "                print(f\"\\nTesting model: {model}\")\n",
    "                \n",
    "                # Create pipeline with this model\n",
    "                test_pipeline = PDFToMarkdownPipeline(model, OLLAMA_BASE_URL)\n",
    "                \n",
    "                # Process page\n",
    "                markdown = test_pipeline.convert_page(test_page)\n",
    "                \n",
    "                results[model] = {\n",
    "                    \"success\": True,\n",
    "                    \"length\": len(markdown),\n",
    "                    \"preview\": markdown[:200] + \"...\" if len(markdown) > 200 else markdown\n",
    "                }\n",
    "                \n",
    "                print(f\"  ✅ Success - {len(markdown)} chars\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[model] = {\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "                print(f\"  ❌ Failed: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run model comparison (only if you have multiple models)\n",
    "if len(test_models) > 1:\n",
    "    model_results = test_model_performance(test_models, PDF_PATH)\n",
    "    \n",
    "    print(\"\\n=== Model Comparison Results ===\")\n",
    "    for model, result in model_results.items():\n",
    "        if result[\"success\"]:\n",
    "            print(f\"{model}: {result['length']} characters\")\n",
    "        else:\n",
    "            print(f\"{model}: FAILED - {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Error handling and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/fberge/OneDrive - Studiecentrum voor Kernenergie/Documents/python/vision-parse/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Error Handling Examples ===\")\n",
    "\n",
    "# Test with non-existent file\n",
    "print(\"Testing with non-existent file...\")\n",
    "bad_result = convert_pdf_to_markdown(\"nonexistent.pdf\", OLLAMA_MODEL, OLLAMA_BASE_URL)\n",
    "print(f\"Expected failure: {not bad_result.success}\")\n",
    "\n",
    "# Test with wrong Ollama URL\n",
    "print(\"\\nTesting with wrong Ollama URL...\")\n",
    "try:\n",
    "    bad_pipeline = PDFToMarkdownPipeline(OLLAMA_MODEL, \"http://localhost:99999\")\n",
    "    # This will fail when we try to use the vision processor\n",
    "    print(\"Pipeline created (will fail on actual processing)\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "\n",
    "# %%\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PDF to Markdown Pipeline Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Path(OUTPUT_DIR).exists():\n",
    "    output_files = list(Path(OUTPUT_DIR).glob(\"*\"))\n",
    "    print(f\"\\nGenerated files in {OUTPUT_DIR}:\")\n",
    "    for file in output_files:\n",
    "        size = file.stat().st_size if file.is_file() else 0\n",
    "        print(f\"  📄 {file.name} ({size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nPipeline ready for production use!\")\n",
    "print(f\"💡 Tip: Adjust PipelineConfig settings for your specific needs\")\n",
    "print(f\"🔧 Remember to tune vision model temperature and DPI settings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
