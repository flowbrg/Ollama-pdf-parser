{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF to Markdown Pipeline - Usage Example Notebook\n",
    "================================================\n",
    "\n",
    "This notebook demonstrates how to use the high-fidelity PDF to Markdown pipeline\n",
    "with LangChain Ollama integration.\n",
    "\n",
    "Prerequisites:\n",
    "- Ollama server running with a vision model (e.g., llama3.2-vision:11b)\n",
    "- Required Python packages: PyMuPDF, langchain-ollama, PIL, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.26.3-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting langchain-ollama\n",
      "  Using cached langchain_ollama-0.3.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pillow\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting ollama<1.0.0,>=0.4.8 (from langchain-ollama)\n",
      "  Using cached ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.60 (from langchain-ollama)\n",
      "  Using cached langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pydantic>=2.7.4 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting httpx>=0.27 (from ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting anyio (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests<3,>=2 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached pymupdf-1.26.3-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "Using cached langchain_ollama-0.3.3-py3-none-any.whl (21 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Using cached langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Using cached ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl (105 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-extensions, tenacity, sniffio, PyYAML, pymupdf, pillow, packaging, orjson, jsonpointer, idna, h11, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, requests-toolbelt, pydantic, httpx, ollama, langsmith, langchain-core, langchain-ollama\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.6.15 charset_normalizer-3.4.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.68 langchain-ollama-0.3.3 langsmith-0.4.4 ollama-0.5.1 orjson-3.10.18 packaging-24.2 pillow-11.3.0 pydantic-2.11.7 pydantic-core-2.33.2 pymupdf-1.26.3 requests-2.32.4 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.14.1 typing-inspection-0.4.1 urllib3-2.5.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install pymupdf langchain-ollama pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline components\n",
    "import sys\n",
    "import fitz\n",
    "sys.path.append('.')  # Adjust path as needed\n",
    "\n",
    "from src.pipeline import (\n",
    "    PDFToMarkdownPipeline, \n",
    "    PipelineConfig,\n",
    "    convert_pdf_to_markdown\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: qwen2.5vl:3b-q4_K_M\n",
      "Ollama server: http://192.168.100.80:1818\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "OLLAMA_MODEL = \"qwen2.5vl:3b-q4_K_M\"  # Change to your preferred model\n",
    "OLLAMA_BASE_URL = \"http://192.168.100.80:1818\"  # Your Ollama server URL\n",
    "PDF_PATH = \"sample_document.pdf\"  # Path to your PDF file\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Using model: {OLLAMA_MODEL}\")\n",
    "print(f\"Ollama server: {OLLAMA_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Simple conversion (recommended for most users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Conversion ===\n",
      "2025-07-05 13:24:17,802 - src.vision_processor - INFO - Connected to Ollama at http://192.168.100.80:1818\n",
      "2025-07-05 13:24:17,802 - src.vision_processor - INFO - VisionProcessor initialized with model: qwen2.5vl:3b-q4_K_M\n",
      "2025-07-05 13:24:17,802 - src.markdown_generator - DEBUG - MarkdownGenerator initialized with config: {'dpi': 300, 'vision_model_temp': 0.1, 'text_extraction_priority': True, 'image_embed_mode': 'base64', 'preserve_formatting': True, 'table_detection_threshold': 0.7, 'formula_detection_threshold': 0.8, 'min_image_size': (50, 50)}\n",
      "2025-07-05 13:24:17,802 - src.pipeline - INFO - Processing PDF with 5 pages...\n",
      "2025-07-05 13:24:17,802 - src.pipeline - INFO - Processing page 1/5\n",
      "2025-07-05 13:24:17,802 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 13:24:17,836 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 13:24:17,838 - src.pdf_analyzer - DEBUG - Has images:False\n",
      "2025-07-05 13:24:17,840 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 13:24:17,842 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 13:24:17,845 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.60)\n",
      "2025-07-05 13:24:17,846 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 13:24:17,850 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 13:24:18,057 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 13:24:18,058 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 13:24:18,059 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 133225\n",
      "2025-07-05 13:24:18,204 - src.pipeline - INFO -     General content extraction...\n",
      "2025-07-05 13:24:18,204 - src.vision_processor - DEBUG - Processing image content with type: general\n",
      "2025-07-05 13:24:18,220 - httpcore.connection - DEBUG - connect_tcp.started host='192.168.100.80' port=1818 local_address=None timeout=None socket_options=None\n",
      "2025-07-05 13:24:18,232 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B4383A8F20>\n",
      "2025-07-05 13:24:18,234 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:18,236 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 13:24:18,237 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:18,238 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 13:24:18,239 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:27,494 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 11:24:27 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 13:24:27,510 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:31,594 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 13:24:31,594 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 13:24:31,594 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 13:24:31,594 - src.vision_processor - DEBUG - Vision model response received, length: 297\n",
      "2025-07-05 13:24:31,594 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 13:24:31,594 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 13:24:31,594 - src.pipeline - INFO - Processing page 2/5\n",
      "2025-07-05 13:24:31,594 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 13:24:31,610 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 13:24:31,614 - src.pdf_analyzer - DEBUG - Has images:False\n",
      "2025-07-05 13:24:31,616 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 13:24:31,617 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 13:24:31,621 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.60)\n",
      "2025-07-05 13:24:31,621 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 13:24:31,624 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 13:24:31,811 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 13:24:31,814 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 13:24:31,815 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 165500\n",
      "2025-07-05 13:24:31,949 - src.pipeline - INFO -     General content extraction...\n",
      "2025-07-05 13:24:31,949 - src.vision_processor - DEBUG - Processing image content with type: general\n",
      "2025-07-05 13:24:31,965 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:31,965 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 13:24:31,965 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:31,965 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 13:24:31,965 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:38,879 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 11:24:38 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 13:24:38,891 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:46,355 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 13:24:46,355 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 13:24:46,355 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 13:24:46,355 - src.vision_processor - DEBUG - Vision model response received, length: 762\n",
      "2025-07-05 13:24:46,355 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 13:24:46,355 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 13:24:46,362 - src.pipeline - INFO - Processing page 3/5\n",
      "2025-07-05 13:24:46,364 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 13:24:46,369 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 13:24:46,371 - src.pdf_analyzer - DEBUG - Has images:False\n",
      "2025-07-05 13:24:46,371 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 13:24:46,379 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 13:24:46,383 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.60)\n",
      "2025-07-05 13:24:46,384 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 13:24:46,390 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 13:24:46,580 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 13:24:46,580 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 13:24:46,580 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 161959\n",
      "2025-07-05 13:24:46,730 - src.pipeline - INFO -     General content extraction...\n",
      "2025-07-05 13:24:46,730 - src.vision_processor - DEBUG - Processing image content with type: general\n",
      "2025-07-05 13:24:46,730 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:46,730 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 13:24:46,730 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:46,730 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 13:24:46,730 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 13:24:53,657 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 11:24:53 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 13:24:53,657 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 13:25:03,798 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 13:25:03,798 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 13:25:03,798 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 13:25:03,798 - src.vision_processor - DEBUG - Vision model response received, length: 871\n",
      "2025-07-05 13:25:03,798 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 13:25:03,812 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 13:25:03,813 - src.pipeline - INFO - Processing page 4/5\n",
      "2025-07-05 13:25:03,814 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 13:25:03,816 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 13:25:03,845 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 13:25:03,845 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 13:25:03,845 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 13:25:03,860 - src.pipeline - INFO -   Strategy: vision_only (confidence: 0.80)\n",
      "2025-07-05 13:25:03,860 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 13:25:04,248 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 13:25:04,248 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 13:25:04,248 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 3835026\n",
      "2025-07-05 13:25:04,452 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 13:25:04,452 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 13:25:04,452 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 13:25:04,466 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 13:25:04,466 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 13:25:04,466 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 13:25:04,483 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 13:25:04,484 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 13:25:11,525 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 11:25:11 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 13:25:11,525 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Simple Conversion ===\")\n",
    "\n",
    "result = convert_pdf_to_markdown(\n",
    "    pdf_path=PDF_PATH,\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    log_level=\"DEBUG\"\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(f\"âœ… Successfully converted {len(result.pages)} pages\")\n",
    "    print(f\"ðŸ“ Output saved to: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"âŒ Conversion failed:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"   - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Advanced usage with custom configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Advanced Configuration ===\n",
      "Pipeline Configuration:\n",
      "  analyzer: PDFAnalyzer\n",
      "  text_extractor: TextExtractor\n",
      "  vision_processor: VisionProcessor\n",
      "  integrator: ContentIntegrator\n",
      "  markdown_generator: MarkdownGenerator\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Advanced Configuration ===\")\n",
    "\n",
    "# Create custom configuration\n",
    "config = PipelineConfig()\n",
    "config.dpi = 400  # Higher resolution for better OCR\n",
    "config.vision_model_temp = 0.1  # Lower temperature for consistent output\n",
    "config.text_extraction_priority = True  # Prefer text extraction when possible\n",
    "config.preserve_formatting = True  # Maintain original formatting\n",
    "config.image_embed_mode = \"base64\"  # Embed images as base64\n",
    "\n",
    "# Initialize pipeline with custom config\n",
    "pipeline = PDFToMarkdownPipeline(\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Show pipeline information\n",
    "print(\"Pipeline Configuration:\")\n",
    "info = pipeline.get_pipeline_info()\n",
    "for component, name in info[\"components\"].items():\n",
    "    print(f\"  {component}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Process single page for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Page Processing ===\n",
      "Analyzing first page...\n",
      "Page Analysis:\n",
      "  - Has extractable text: True\n",
      "  - Text coverage: 0.12\n",
      "  - Has images: False\n",
      "  - Has tables: False\n",
      "  - Has formulas: False\n",
      "  - Layout complexity: 0.90\n",
      "  - Recommended strategy: vision_only\n",
      "  - Confidence: 0.80\n",
      "\n",
      "Processing page...\n",
      "  Analyzing page structure...\n",
      "  Strategy: vision_only (confidence: 0.80)\n",
      "  Processing with vision model...\n",
      "    General content extraction...\n",
      "  Integrating content...\n",
      "  Generating markdown...\n",
      "\n",
      "Generated markdown (0 characters):\n",
      "==================================================\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Single Page Processing ===\")\n",
    "\n",
    "import fitz\n",
    "\n",
    "# Open PDF and process first page only\n",
    "with  fitz.open(PDF_PATH) as doc:\n",
    "    if doc.page_count > 0:\n",
    "        first_page = doc[0]\n",
    "        \n",
    "        print(\"Analyzing first page...\")\n",
    "        analysis = pipeline.analyzer.analyze_page_content(first_page)\n",
    "        \n",
    "        print(f\"Page Analysis:\")\n",
    "        print(f\"  - Has extractable text: {analysis.has_extractable_text}\")\n",
    "        print(f\"  - Text coverage: {analysis.text_coverage:.2f}\")\n",
    "        print(f\"  - Has images: {analysis.has_images}\")\n",
    "        print(f\"  - Has tables: {analysis.has_tables}\")\n",
    "        print(f\"  - Has formulas: {analysis.has_formulas}\")\n",
    "        print(f\"  - Layout complexity: {analysis.layout_complexity:.2f}\")\n",
    "        print(f\"  - Recommended strategy: {analysis.strategy.value}\")\n",
    "        print(f\"  - Confidence: {analysis.confidence:.2f}\")\n",
    "        \n",
    "        # Process the page\n",
    "        print(\"\\nProcessing page...\")\n",
    "        page_markdown = pipeline.convert_page(first_page)\n",
    "        \n",
    "        print(f\"\\nGenerated markdown ({len(page_markdown)} characters):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(page_markdown[:500] + \"...\" if len(page_markdown) > 500 else page_markdown)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Batch processing with custom content handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch Processing with Content Analysis ===\n",
      "Analyzing PDF structure (1 pages)...\n",
      "Page 1: vision_only (conf: 0.80, complex: 0.90)\n",
      "\n",
      "Strategy Distribution:\n",
      "  vision_only: 1 pages\n",
      "\n",
      "Average layout complexity: 0.90\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Batch Processing with Content Analysis ===\")\n",
    "\n",
    "def analyze_pdf_structure(pdf_path: str):\n",
    "    \"\"\"Analyze entire PDF structure before processing\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        analyses = {}\n",
    "        \n",
    "        print(f\"Analyzing PDF structure ({doc.page_count} pages)...\")\n",
    "        \n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc[page_num]\n",
    "            analysis = pipeline.analyzer.analyze_page_content(page)\n",
    "            analyses[page_num] = analysis\n",
    "            \n",
    "            print(f\"Page {page_num + 1}: {analysis.strategy.value} \"\n",
    "                f\"(conf: {analysis.confidence:.2f}, \"\n",
    "                f\"complex: {analysis.layout_complexity:.2f})\")\n",
    "    \n",
    "    return analyses\n",
    "\n",
    "# Analyze structure first\n",
    "if Path(PDF_PATH).exists():\n",
    "    pdf_analyses = analyze_pdf_structure(PDF_PATH)\n",
    "    \n",
    "    # Show summary statistics\n",
    "    strategies = [a.strategy.value for a in pdf_analyses.values()]\n",
    "    strategy_counts = {s: strategies.count(s) for s in set(strategies)}\n",
    "    \n",
    "    print(\"\\nStrategy Distribution:\")\n",
    "    for strategy, count in strategy_counts.items():\n",
    "        print(f\"  {strategy}: {count} pages\")\n",
    "    \n",
    "    avg_complexity = sum(a.layout_complexity for a in pdf_analyses.values()) / len(pdf_analyses)\n",
    "    print(f\"\\nAverage layout complexity: {avg_complexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5: Testing different vision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "\n",
      "Testing model: llama3.2-vision:11b\n",
      "  Analyzing page structure...\n",
      "  Strategy: vision_only (confidence: 0.80)\n",
      "  Processing with vision model...\n",
      "    Describing diagrams...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Model Comparison ===\")\n",
    "\n",
    "# List of models to test (uncomment available models)\n",
    "test_models = [\n",
    "    \"llama3.2-vision:11b\",\n",
    "    \"qwen2.5vl:3b-q4_K_M\",\n",
    "    # \"llava:13b\",\n",
    "    # \"bakllava\",\n",
    "]\n",
    "\n",
    "def test_model_performance(models: list, test_pdf: str):\n",
    "    \"\"\"Test different models on the same page\"\"\"\n",
    "    if not Path(test_pdf).exists():\n",
    "        print(f\"Test PDF not found: {test_pdf}\")\n",
    "        return\n",
    "    \n",
    "    with fitz.open(test_pdf) as doc:\n",
    "        test_page = doc[0]  # Use first page for testing\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for model in models:\n",
    "            try:\n",
    "                print(f\"\\nTesting model: {model}\")\n",
    "                \n",
    "                # Create pipeline with this model\n",
    "                test_pipeline = PDFToMarkdownPipeline(model, OLLAMA_BASE_URL)\n",
    "                \n",
    "                # Process page\n",
    "                markdown = test_pipeline.convert_page(test_page)\n",
    "                \n",
    "                results[model] = {\n",
    "                    \"success\": True,\n",
    "                    \"length\": len(markdown),\n",
    "                    \"preview\": markdown[:200] + \"...\" if len(markdown) > 200 else markdown\n",
    "                }\n",
    "                \n",
    "                print(f\"  âœ… Success - {len(markdown)} chars\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[model] = {\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "                print(f\"  âŒ Failed: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run model comparison (only if you have multiple models)\n",
    "if len(test_models) > 1:\n",
    "    model_results = test_model_performance(test_models, PDF_PATH)\n",
    "    \n",
    "    print(\"\\n=== Model Comparison Results ===\")\n",
    "    for model, result in model_results.items():\n",
    "        if result[\"success\"]:\n",
    "            print(f\"{model}: {result['length']} characters\")\n",
    "        else:\n",
    "            print(f\"{model}: FAILED - {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6: Content-specific extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Content-Specific Extraction ===\n",
      "\n",
      "Processing page 1 for specific content...\n",
      "  âœ… Found tables\n",
      "  âœ… Found formulas\n",
      "  âœ… Found diagrams\n",
      "\n",
      "=== Extraction Summary ===\n",
      "Tables: 1 found\n",
      "  Page 1: | Keywords | Systems engineering | Systems engineering | Systems engineering | Systems engineering |...\n",
      "Formulas: 1 found\n",
      "  Page 1: The image contains a document from the Annals of Nuclear Energy journal. The document discusses the ...\n",
      "Diagrams: 1 found\n",
      "  Page 1: # Flowchart Description\n",
      "\n",
      "## Overview\n",
      "This flowchart outlines the stages of the MYRRHA project, a mul...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Content-Specific Extraction ===\")\n",
    "\n",
    "def extract_specific_content(pdf_path: str, content_types: list):\n",
    "    \"\"\"Extract only specific types of content\"\"\"\n",
    "    if not Path(pdf_path).exists():\n",
    "        print(f\"PDF not found: {pdf_path}\")\n",
    "        return\n",
    "    \n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        extracted_content = {content_type: [] for content_type in content_types}\n",
    "        \n",
    "        for page_num in range(min(3, doc.page_count)):  # Test first 3 pages\n",
    "            page = doc[page_num]\n",
    "            page_image = pipeline.vision_processor.chat_model\n",
    "            \n",
    "            # Convert page to image for vision processing\n",
    "            from src.utils import Utils\n",
    "            page_image_b64 = Utils.extract_page_image(page, 300)\n",
    "            \n",
    "            print(f\"\\nProcessing page {page_num + 1} for specific content...\")\n",
    "            \n",
    "            for content_type in content_types:\n",
    "                try:\n",
    "                    if content_type == \"tables\":\n",
    "                        result = pipeline.vision_processor.extract_table_data(page_image_b64)\n",
    "                    elif content_type == \"formulas\":\n",
    "                        result = pipeline.vision_processor.extract_formulas(page_image_b64)\n",
    "                    elif content_type == \"diagrams\":\n",
    "                        result = pipeline.vision_processor.describe_diagrams(page_image_b64)\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    if result.content.strip():\n",
    "                        extracted_content[content_type].append({\n",
    "                            \"page\": page_num + 1,\n",
    "                            \"content\": result.content,\n",
    "                            \"confidence\": result.confidence\n",
    "                        })\n",
    "                        print(f\"  âœ… Found {content_type}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ Error extracting {content_type}: {e}\")\n",
    "    \n",
    "    return extracted_content\n",
    "\n",
    "# Extract specific content types\n",
    "content_types = [\"tables\", \"formulas\", \"diagrams\"]\n",
    "specific_content = extract_specific_content(PDF_PATH, content_types)\n",
    "\n",
    "print(\"\\n=== Extraction Summary ===\")\n",
    "for content_type, items in specific_content.items():\n",
    "    print(f\"{content_type.title()}: {len(items)} found\")\n",
    "    for item in items[:2]:  # Show first 2 items\n",
    "        preview = item[\"content\"][:100] + \"...\" if len(item[\"content\"]) > 100 else item[\"content\"]\n",
    "        print(f\"  Page {item['page']}: {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7: Error handling and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/fberge/OneDrive - Studiecentrum voor Kernenergie/Documents/python/vision-parse/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Error Handling Examples ===\")\n",
    "\n",
    "# Test with non-existent file\n",
    "print(\"Testing with non-existent file...\")\n",
    "bad_result = convert_pdf_to_markdown(\"nonexistent.pdf\", OLLAMA_MODEL, OLLAMA_BASE_URL)\n",
    "print(f\"Expected failure: {not bad_result.success}\")\n",
    "\n",
    "# Test with wrong Ollama URL\n",
    "print(\"\\nTesting with wrong Ollama URL...\")\n",
    "try:\n",
    "    bad_pipeline = PDFToMarkdownPipeline(OLLAMA_MODEL, \"http://localhost:99999\")\n",
    "    # This will fail when we try to use the vision processor\n",
    "    print(\"Pipeline created (will fail on actual processing)\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "\n",
    "# %%\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PDF to Markdown Pipeline Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Path(OUTPUT_DIR).exists():\n",
    "    output_files = list(Path(OUTPUT_DIR).glob(\"*\"))\n",
    "    print(f\"\\nGenerated files in {OUTPUT_DIR}:\")\n",
    "    for file in output_files:\n",
    "        size = file.stat().st_size if file.is_file() else 0\n",
    "        print(f\"  ðŸ“„ {file.name} ({size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nPipeline ready for production use!\")\n",
    "print(f\"ðŸ’¡ Tip: Adjust PipelineConfig settings for your specific needs\")\n",
    "print(f\"ðŸ”§ Remember to tune vision model temperature and DPI settings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
