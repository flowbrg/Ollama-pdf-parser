{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF to Markdown Pipeline - Usage Example Notebook\n",
    "================================================\n",
    "\n",
    "This notebook demonstrates how to use the high-fidelity PDF to Markdown pipeline\n",
    "with LangChain Ollama integration.\n",
    "\n",
    "Prerequisites:\n",
    "- Ollama server running with a vision model (e.g., llama3.2-vision:11b)\n",
    "- Required Python packages: PyMuPDF, langchain-ollama, PIL, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install PyMuPDF langchain-ollama pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline components\n",
    "import sys\n",
    "sys.path.append('.')  # Adjust path as needed\n",
    "\n",
    "from src.pipeline import (\n",
    "    PDFToMarkdownPipeline, \n",
    "    PipelineConfig,\n",
    "    convert_pdf_to_markdown\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "OLLAMA_MODEL = \"llama3.2-vision:11b\"  # Change to your preferred model\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"  # Your Ollama server URL\n",
    "PDF_PATH = \"sample_document.pdf\"  # Path to your PDF file\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "print(f\"Using model: {OLLAMA_MODEL}\")\n",
    "print(f\"Ollama server: {OLLAMA_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Simple conversion (recommended for most users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Simple Conversion ===\")\n",
    "\n",
    "result = convert_pdf_to_markdown(\n",
    "    pdf_path=PDF_PATH,\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(f\"âœ… Successfully converted {len(result.pages)} pages\")\n",
    "    print(f\"ðŸ“ Output saved to: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"âŒ Conversion failed:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"   - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Advanced usage with custom configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Advanced Configuration ===\")\n",
    "\n",
    "# Create custom configuration\n",
    "config = PipelineConfig()\n",
    "config.dpi = 400  # Higher resolution for better OCR\n",
    "config.vision_model_temp = 0.1  # Lower temperature for consistent output\n",
    "config.text_extraction_priority = True  # Prefer text extraction when possible\n",
    "config.preserve_formatting = True  # Maintain original formatting\n",
    "config.image_embed_mode = \"base64\"  # Embed images as base64\n",
    "\n",
    "# Initialize pipeline with custom config\n",
    "pipeline = PDFToMarkdownPipeline(\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Show pipeline information\n",
    "print(\"Pipeline Configuration:\")\n",
    "info = pipeline.get_pipeline_info()\n",
    "for component, name in info[\"components\"].items():\n",
    "    print(f\"  {component}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Process single page for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Single Page Processing ===\")\n",
    "\n",
    "import fitz\n",
    "\n",
    "# Open PDF and process first page only\n",
    "doc = fitz.open(PDF_PATH)\n",
    "if doc.page_count > 0:\n",
    "    first_page = doc[0]\n",
    "    \n",
    "    print(\"Analyzing first page...\")\n",
    "    analysis = pipeline.analyzer.analyze_page_content(first_page)\n",
    "    \n",
    "    print(f\"Page Analysis:\")\n",
    "    print(f\"  - Has extractable text: {analysis.has_extractable_text}\")\n",
    "    print(f\"  - Text coverage: {analysis.text_coverage:.2f}\")\n",
    "    print(f\"  - Has images: {analysis.has_images}\")\n",
    "    print(f\"  - Has tables: {analysis.has_tables}\")\n",
    "    print(f\"  - Has formulas: {analysis.has_formulas}\")\n",
    "    print(f\"  - Layout complexity: {analysis.layout_complexity:.2f}\")\n",
    "    print(f\"  - Recommended strategy: {analysis.strategy.value}\")\n",
    "    print(f\"  - Confidence: {analysis.confidence:.2f}\")\n",
    "    \n",
    "    # Process the page\n",
    "    print(\"\\nProcessing page...\")\n",
    "    page_markdown = pipeline.convert_page(first_page)\n",
    "    \n",
    "    print(f\"\\nGenerated markdown ({len(page_markdown)} characters):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(page_markdown[:500] + \"...\" if len(page_markdown) > 500 else page_markdown)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Batch processing with custom content handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Batch Processing with Content Analysis ===\")\n",
    "\n",
    "def analyze_pdf_structure(pdf_path: str):\n",
    "    \"\"\"Analyze entire PDF structure before processing\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    analyses = {}\n",
    "    \n",
    "    print(f\"Analyzing PDF structure ({doc.page_count} pages)...\")\n",
    "    \n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        analysis = pipeline.analyzer.analyze_page_content(page)\n",
    "        analyses[page_num] = analysis\n",
    "        \n",
    "        print(f\"Page {page_num + 1}: {analysis.strategy.value} \"\n",
    "              f\"(conf: {analysis.confidence:.2f}, \"\n",
    "              f\"complex: {analysis.layout_complexity:.2f})\")\n",
    "    \n",
    "    doc.close()\n",
    "    return analyses\n",
    "\n",
    "# Analyze structure first\n",
    "if Path(PDF_PATH).exists():\n",
    "    pdf_analyses = analyze_pdf_structure(PDF_PATH)\n",
    "    \n",
    "    # Show summary statistics\n",
    "    strategies = [a.strategy.value for a in pdf_analyses.values()]\n",
    "    strategy_counts = {s: strategies.count(s) for s in set(strategies)}\n",
    "    \n",
    "    print(\"\\nStrategy Distribution:\")\n",
    "    for strategy, count in strategy_counts.items():\n",
    "        print(f\"  {strategy}: {count} pages\")\n",
    "    \n",
    "    avg_complexity = sum(a.layout_complexity for a in pdf_analyses.values()) / len(pdf_analyses)\n",
    "    print(f\"\\nAverage layout complexity: {avg_complexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5: Testing different vision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Model Comparison ===\")\n",
    "\n",
    "# List of models to test (uncomment available models)\n",
    "test_models = [\n",
    "    \"llama3.2-vision:11b\",\n",
    "    # \"llava:13b\",\n",
    "    # \"bakllava\",\n",
    "]\n",
    "\n",
    "def test_model_performance(models: list, test_pdf: str):\n",
    "    \"\"\"Test different models on the same page\"\"\"\n",
    "    if not Path(test_pdf).exists():\n",
    "        print(f\"Test PDF not found: {test_pdf}\")\n",
    "        return\n",
    "    \n",
    "    doc = fitz.open(test_pdf)\n",
    "    test_page = doc[0]  # Use first page for testing\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model in models:\n",
    "        try:\n",
    "            print(f\"\\nTesting model: {model}\")\n",
    "            \n",
    "            # Create pipeline with this model\n",
    "            test_pipeline = PDFToMarkdownPipeline(model, OLLAMA_BASE_URL)\n",
    "            \n",
    "            # Process page\n",
    "            markdown = test_pipeline.convert_page(test_page)\n",
    "            \n",
    "            results[model] = {\n",
    "                \"success\": True,\n",
    "                \"length\": len(markdown),\n",
    "                \"preview\": markdown[:200] + \"...\" if len(markdown) > 200 else markdown\n",
    "            }\n",
    "            \n",
    "            print(f\"  âœ… Success - {len(markdown)} chars\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            results[model] = {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "            print(f\"  âŒ Failed: {e}\")\n",
    "    \n",
    "    doc.close()\n",
    "    return results\n",
    "\n",
    "# Run model comparison (only if you have multiple models)\n",
    "if len(test_models) > 1:\n",
    "    model_results = test_model_performance(test_models, PDF_PATH)\n",
    "    \n",
    "    print(\"\\n=== Model Comparison Results ===\")\n",
    "    for model, result in model_results.items():\n",
    "        if result[\"success\"]:\n",
    "            print(f\"{model}: {result['length']} characters\")\n",
    "        else:\n",
    "            print(f\"{model}: FAILED - {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6: Content-specific extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Content-Specific Extraction ===\")\n",
    "\n",
    "def extract_specific_content(pdf_path: str, content_types: list):\n",
    "    \"\"\"Extract only specific types of content\"\"\"\n",
    "    if not Path(pdf_path).exists():\n",
    "        print(f\"PDF not found: {pdf_path}\")\n",
    "        return\n",
    "    \n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_content = {content_type: [] for content_type in content_types}\n",
    "    \n",
    "    for page_num in range(min(3, doc.page_count)):  # Test first 3 pages\n",
    "        page = doc[page_num]\n",
    "        page_image = pipeline.vision_processor.chat_model\n",
    "        \n",
    "        # Convert page to image for vision processing\n",
    "        from utils import Utils\n",
    "        page_image_b64 = Utils.extract_page_image(page, 300)\n",
    "        \n",
    "        print(f\"\\nProcessing page {page_num + 1} for specific content...\")\n",
    "        \n",
    "        for content_type in content_types:\n",
    "            try:\n",
    "                if content_type == \"tables\":\n",
    "                    result = pipeline.vision_processor.extract_table_data(page_image_b64)\n",
    "                elif content_type == \"formulas\":\n",
    "                    result = pipeline.vision_processor.extract_formulas(page_image_b64)\n",
    "                elif content_type == \"diagrams\":\n",
    "                    result = pipeline.vision_processor.describe_diagrams(page_image_b64)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                if result.content.strip():\n",
    "                    extracted_content[content_type].append({\n",
    "                        \"page\": page_num + 1,\n",
    "                        \"content\": result.content,\n",
    "                        \"confidence\": result.confidence\n",
    "                    })\n",
    "                    print(f\"  âœ… Found {content_type}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ Error extracting {content_type}: {e}\")\n",
    "    \n",
    "    doc.close()\n",
    "    return extracted_content\n",
    "\n",
    "# Extract specific content types\n",
    "content_types = [\"tables\", \"formulas\", \"diagrams\"]\n",
    "specific_content = extract_specific_content(PDF_PATH, content_types)\n",
    "\n",
    "print(\"\\n=== Extraction Summary ===\")\n",
    "for content_type, items in specific_content.items():\n",
    "    print(f\"{content_type.title()}: {len(items)} found\")\n",
    "    for item in items[:2]:  # Show first 2 items\n",
    "        preview = item[\"content\"][:100] + \"...\" if len(item[\"content\"]) > 100 else item[\"content\"]\n",
    "        print(f\"  Page {item['page']}: {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7: Error handling and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Error Handling Examples ===\")\n",
    "\n",
    "# Test with non-existent file\n",
    "print(\"Testing with non-existent file...\")\n",
    "bad_result = convert_pdf_to_markdown(\"nonexistent.pdf\", OLLAMA_MODEL, OLLAMA_BASE_URL)\n",
    "print(f\"Expected failure: {not bad_result.success}\")\n",
    "\n",
    "# Test with wrong Ollama URL\n",
    "print(\"\\nTesting with wrong Ollama URL...\")\n",
    "try:\n",
    "    bad_pipeline = PDFToMarkdownPipeline(OLLAMA_MODEL, \"http://localhost:99999\")\n",
    "    # This will fail when we try to use the vision processor\n",
    "    print(\"Pipeline created (will fail on actual processing)\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "\n",
    "# %%\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PDF to Markdown Pipeline Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Path(OUTPUT_DIR).exists():\n",
    "    output_files = list(Path(OUTPUT_DIR).glob(\"*\"))\n",
    "    print(f\"\\nGenerated files in {OUTPUT_DIR}:\")\n",
    "    for file in output_files:\n",
    "        size = file.stat().st_size if file.is_file() else 0\n",
    "        print(f\"  ðŸ“„ {file.name} ({size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nPipeline ready for production use!\")\n",
    "print(f\"ðŸ’¡ Tip: Adjust PipelineConfig settings for your specific needs\")\n",
    "print(f\"ðŸ”§ Remember to tune vision model temperature and DPI settings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
