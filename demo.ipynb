{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF to Markdown Pipeline - Usage Example Notebook\n",
    "================================================\n",
    "\n",
    "This notebook demonstrates how to use the high-fidelity PDF to Markdown pipeline\n",
    "with LangChain Ollama integration.\n",
    "\n",
    "Prerequisites:\n",
    "- Ollama server running with a vision model (e.g., llama3.2-vision:11b)\n",
    "- Required Python packages: PyMuPDF, langchain-ollama, PIL, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-ollama) (0.5.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.60 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-ollama) (0.3.68)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (4.14.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.11.7)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from ollama<1.0.0,>=0.4.8->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\fberge\\onedrive - studiecentrum voor kernenergie\\documents\\python\\vision-parse\\.venv\\lib\\site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install PyMuPDF langchain-ollama pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline components\n",
    "import sys\n",
    "sys.path.append('.')  # Adjust path as needed\n",
    "\n",
    "from src.pipeline import (\n",
    "    PDFToMarkdownPipeline, \n",
    "    PipelineConfig,\n",
    "    convert_pdf_to_markdown\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: qwen2.5vl:3b-q4_K_M\n",
      "Ollama server: http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "OLLAMA_MODEL = \"qwen2.5vl:3b-q4_K_M\"  # Change to your preferred model\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"  # Your Ollama server URL\n",
    "PDF_PATH = \"sample_document.pdf\"  # Path to your PDF file\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "print(f\"Using model: {OLLAMA_MODEL}\")\n",
    "print(f\"Ollama server: {OLLAMA_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Simple conversion (recommended for most users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Conversion ===\n",
      "Processing PDF with 1 pages...\n",
      "Processing page 1/1\n",
      "  Analyzing page structure...\n",
      "  Strategy: vision_only (confidence: 0.80)\n",
      "  Processing with vision model...\n",
      "    Describing diagrams...\n",
      "  Integrating content...\n",
      "  Generating markdown...\n",
      "Conversion completed! Files saved to ./output\n",
      "  - output\\page_001.md\n",
      "  - output\\combined_document.md\n",
      "  - output\\conversion_metadata.json\n",
      "✅ Successfully converted 1 pages\n",
      "📁 Output saved to: ./output\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Simple Conversion ===\")\n",
    "\n",
    "result = convert_pdf_to_markdown(\n",
    "    pdf_path=PDF_PATH,\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(f\"✅ Successfully converted {len(result.pages)} pages\")\n",
    "    print(f\"📁 Output saved to: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"❌ Conversion failed:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"   - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Advanced usage with custom configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Advanced Configuration ===\n",
      "Pipeline Configuration:\n",
      "  analyzer: PDFAnalyzer\n",
      "  text_extractor: TextExtractor\n",
      "  vision_processor: VisionProcessor\n",
      "  integrator: ContentIntegrator\n",
      "  markdown_generator: MarkdownGenerator\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Advanced Configuration ===\")\n",
    "\n",
    "# Create custom configuration\n",
    "config = PipelineConfig()\n",
    "config.dpi = 400  # Higher resolution for better OCR\n",
    "config.vision_model_temp = 0.1  # Lower temperature for consistent output\n",
    "config.text_extraction_priority = True  # Prefer text extraction when possible\n",
    "config.preserve_formatting = True  # Maintain original formatting\n",
    "config.image_embed_mode = \"base64\"  # Embed images as base64\n",
    "\n",
    "# Initialize pipeline with custom config\n",
    "pipeline = PDFToMarkdownPipeline(\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Show pipeline information\n",
    "print(\"Pipeline Configuration:\")\n",
    "info = pipeline.get_pipeline_info()\n",
    "for component, name in info[\"components\"].items():\n",
    "    print(f\"  {component}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Process single page for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Page Processing ===\n",
      "Analyzing first page...\n",
      "Page Analysis:\n",
      "  - Has extractable text: True\n",
      "  - Text coverage: 0.41\n",
      "  - Has images: True\n",
      "  - Has tables: False\n",
      "  - Has formulas: False\n",
      "  - Layout complexity: 0.90\n",
      "  - Recommended strategy: vision_only\n",
      "  - Confidence: 0.80\n",
      "\n",
      "Processing page...\n",
      "  Analyzing page structure...\n",
      "  Strategy: vision_only (confidence: 0.80)\n",
      "  Processing with vision model...\n",
      "    Describing diagrams...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Single Page Processing ===\")\n",
    "\n",
    "import fitz\n",
    "\n",
    "# Open PDF and process first page only\n",
    "doc = fitz.open(PDF_PATH)\n",
    "if doc.page_count > 0:\n",
    "    first_page = doc[0]\n",
    "    \n",
    "    print(\"Analyzing first page...\")\n",
    "    analysis = pipeline.analyzer.analyze_page_content(first_page)\n",
    "    \n",
    "    print(f\"Page Analysis:\")\n",
    "    print(f\"  - Has extractable text: {analysis.has_extractable_text}\")\n",
    "    print(f\"  - Text coverage: {analysis.text_coverage:.2f}\")\n",
    "    print(f\"  - Has images: {analysis.has_images}\")\n",
    "    print(f\"  - Has tables: {analysis.has_tables}\")\n",
    "    print(f\"  - Has formulas: {analysis.has_formulas}\")\n",
    "    print(f\"  - Layout complexity: {analysis.layout_complexity:.2f}\")\n",
    "    print(f\"  - Recommended strategy: {analysis.strategy.value}\")\n",
    "    print(f\"  - Confidence: {analysis.confidence:.2f}\")\n",
    "    \n",
    "    # Process the page\n",
    "    print(\"\\nProcessing page...\")\n",
    "    page_markdown = pipeline.convert_page(first_page)\n",
    "    \n",
    "    print(f\"\\nGenerated markdown ({len(page_markdown)} characters):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(page_markdown[:500] + \"...\" if len(page_markdown) > 500 else page_markdown)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Batch processing with custom content handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Batch Processing with Content Analysis ===\")\n",
    "\n",
    "def analyze_pdf_structure(pdf_path: str):\n",
    "    \"\"\"Analyze entire PDF structure before processing\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    analyses = {}\n",
    "    \n",
    "    print(f\"Analyzing PDF structure ({doc.page_count} pages)...\")\n",
    "    \n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        analysis = pipeline.analyzer.analyze_page_content(page)\n",
    "        analyses[page_num] = analysis\n",
    "        \n",
    "        print(f\"Page {page_num + 1}: {analysis.strategy.value} \"\n",
    "              f\"(conf: {analysis.confidence:.2f}, \"\n",
    "              f\"complex: {analysis.layout_complexity:.2f})\")\n",
    "    \n",
    "    doc.close()\n",
    "    return analyses\n",
    "\n",
    "# Analyze structure first\n",
    "if Path(PDF_PATH).exists():\n",
    "    pdf_analyses = analyze_pdf_structure(PDF_PATH)\n",
    "    \n",
    "    # Show summary statistics\n",
    "    strategies = [a.strategy.value for a in pdf_analyses.values()]\n",
    "    strategy_counts = {s: strategies.count(s) for s in set(strategies)}\n",
    "    \n",
    "    print(\"\\nStrategy Distribution:\")\n",
    "    for strategy, count in strategy_counts.items():\n",
    "        print(f\"  {strategy}: {count} pages\")\n",
    "    \n",
    "    avg_complexity = sum(a.layout_complexity for a in pdf_analyses.values()) / len(pdf_analyses)\n",
    "    print(f\"\\nAverage layout complexity: {avg_complexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5: Testing different vision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Model Comparison ===\")\n",
    "\n",
    "# List of models to test (uncomment available models)\n",
    "test_models = [\n",
    "    \"llama3.2-vision:11b\",\n",
    "    # \"llava:13b\",\n",
    "    # \"bakllava\",\n",
    "]\n",
    "\n",
    "def test_model_performance(models: list, test_pdf: str):\n",
    "    \"\"\"Test different models on the same page\"\"\"\n",
    "    if not Path(test_pdf).exists():\n",
    "        print(f\"Test PDF not found: {test_pdf}\")\n",
    "        return\n",
    "    \n",
    "    doc = fitz.open(test_pdf)\n",
    "    test_page = doc[0]  # Use first page for testing\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model in models:\n",
    "        try:\n",
    "            print(f\"\\nTesting model: {model}\")\n",
    "            \n",
    "            # Create pipeline with this model\n",
    "            test_pipeline = PDFToMarkdownPipeline(model, OLLAMA_BASE_URL)\n",
    "            \n",
    "            # Process page\n",
    "            markdown = test_pipeline.convert_page(test_page)\n",
    "            \n",
    "            results[model] = {\n",
    "                \"success\": True,\n",
    "                \"length\": len(markdown),\n",
    "                \"preview\": markdown[:200] + \"...\" if len(markdown) > 200 else markdown\n",
    "            }\n",
    "            \n",
    "            print(f\"  ✅ Success - {len(markdown)} chars\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            results[model] = {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "            print(f\"  ❌ Failed: {e}\")\n",
    "    \n",
    "    doc.close()\n",
    "    return results\n",
    "\n",
    "# Run model comparison (only if you have multiple models)\n",
    "if len(test_models) > 1:\n",
    "    model_results = test_model_performance(test_models, PDF_PATH)\n",
    "    \n",
    "    print(\"\\n=== Model Comparison Results ===\")\n",
    "    for model, result in model_results.items():\n",
    "        if result[\"success\"]:\n",
    "            print(f\"{model}: {result['length']} characters\")\n",
    "        else:\n",
    "            print(f\"{model}: FAILED - {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6: Content-specific extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Content-Specific Extraction ===\")\n",
    "\n",
    "def extract_specific_content(pdf_path: str, content_types: list):\n",
    "    \"\"\"Extract only specific types of content\"\"\"\n",
    "    if not Path(pdf_path).exists():\n",
    "        print(f\"PDF not found: {pdf_path}\")\n",
    "        return\n",
    "    \n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_content = {content_type: [] for content_type in content_types}\n",
    "    \n",
    "    for page_num in range(min(3, doc.page_count)):  # Test first 3 pages\n",
    "        page = doc[page_num]\n",
    "        page_image = pipeline.vision_processor.chat_model\n",
    "        \n",
    "        # Convert page to image for vision processing\n",
    "        from utils import Utils\n",
    "        page_image_b64 = Utils.extract_page_image(page, 300)\n",
    "        \n",
    "        print(f\"\\nProcessing page {page_num + 1} for specific content...\")\n",
    "        \n",
    "        for content_type in content_types:\n",
    "            try:\n",
    "                if content_type == \"tables\":\n",
    "                    result = pipeline.vision_processor.extract_table_data(page_image_b64)\n",
    "                elif content_type == \"formulas\":\n",
    "                    result = pipeline.vision_processor.extract_formulas(page_image_b64)\n",
    "                elif content_type == \"diagrams\":\n",
    "                    result = pipeline.vision_processor.describe_diagrams(page_image_b64)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                if result.content.strip():\n",
    "                    extracted_content[content_type].append({\n",
    "                        \"page\": page_num + 1,\n",
    "                        \"content\": result.content,\n",
    "                        \"confidence\": result.confidence\n",
    "                    })\n",
    "                    print(f\"  ✅ Found {content_type}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ Error extracting {content_type}: {e}\")\n",
    "    \n",
    "    doc.close()\n",
    "    return extracted_content\n",
    "\n",
    "# Extract specific content types\n",
    "content_types = [\"tables\", \"formulas\", \"diagrams\"]\n",
    "specific_content = extract_specific_content(PDF_PATH, content_types)\n",
    "\n",
    "print(\"\\n=== Extraction Summary ===\")\n",
    "for content_type, items in specific_content.items():\n",
    "    print(f\"{content_type.title()}: {len(items)} found\")\n",
    "    for item in items[:2]:  # Show first 2 items\n",
    "        preview = item[\"content\"][:100] + \"...\" if len(item[\"content\"]) > 100 else item[\"content\"]\n",
    "        print(f\"  Page {item['page']}: {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7: Error handling and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/fberge/OneDrive - Studiecentrum voor Kernenergie/Documents/python/vision-parse/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Error Handling Examples ===\")\n",
    "\n",
    "# Test with non-existent file\n",
    "print(\"Testing with non-existent file...\")\n",
    "bad_result = convert_pdf_to_markdown(\"nonexistent.pdf\", OLLAMA_MODEL, OLLAMA_BASE_URL)\n",
    "print(f\"Expected failure: {not bad_result.success}\")\n",
    "\n",
    "# Test with wrong Ollama URL\n",
    "print(\"\\nTesting with wrong Ollama URL...\")\n",
    "try:\n",
    "    bad_pipeline = PDFToMarkdownPipeline(OLLAMA_MODEL, \"http://localhost:99999\")\n",
    "    # This will fail when we try to use the vision processor\n",
    "    print(\"Pipeline created (will fail on actual processing)\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "\n",
    "# %%\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PDF to Markdown Pipeline Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Path(OUTPUT_DIR).exists():\n",
    "    output_files = list(Path(OUTPUT_DIR).glob(\"*\"))\n",
    "    print(f\"\\nGenerated files in {OUTPUT_DIR}:\")\n",
    "    for file in output_files:\n",
    "        size = file.stat().st_size if file.is_file() else 0\n",
    "        print(f\"  📄 {file.name} ({size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nPipeline ready for production use!\")\n",
    "print(f\"💡 Tip: Adjust PipelineConfig settings for your specific needs\")\n",
    "print(f\"🔧 Remember to tune vision model temperature and DPI settings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
