{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF to Markdown Pipeline - Usage Example Notebook\n",
    "================================================\n",
    "\n",
    "This notebook demonstrates how to use the high-fidelity PDF to Markdown pipeline\n",
    "with LangChain Ollama integration.\n",
    "\n",
    "Prerequisites:\n",
    "- Ollama server running with a vision model (e.g., llama3.2-vision:11b)\n",
    "- Required Python packages: PyMuPDF, langchain-ollama, PIL, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.26.3-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting langchain-ollama\n",
      "  Using cached langchain_ollama-0.3.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pillow\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting ollama<1.0.0,>=0.4.8 (from langchain-ollama)\n",
      "  Using cached ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.60 (from langchain-ollama)\n",
      "  Using cached langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pydantic>=2.7.4 (from langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting httpx>=0.27 (from ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting anyio (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests<3,>=2 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached pymupdf-1.26.3-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "Using cached langchain_ollama-0.3.3-py3-none-any.whl (21 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Using cached langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Using cached ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl (105 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-extensions, tenacity, sniffio, PyYAML, pymupdf, pillow, packaging, orjson, jsonpointer, idna, h11, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, requests-toolbelt, pydantic, httpx, ollama, langsmith, langchain-core, langchain-ollama\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.6.15 charset_normalizer-3.4.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.68 langchain-ollama-0.3.3 langsmith-0.4.4 ollama-0.5.1 orjson-3.10.18 packaging-24.2 pillow-11.3.0 pydantic-2.11.7 pydantic-core-2.33.2 pymupdf-1.26.3 requests-2.32.4 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.14.1 typing-inspection-0.4.1 urllib3-2.5.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install pymupdf langchain-ollama pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline components\n",
    "import sys\n",
    "import fitz\n",
    "sys.path.append('.')  # Adjust path as needed\n",
    "\n",
    "from src.pipeline import (\n",
    "    PDFToMarkdownPipeline, \n",
    "    PipelineConfig,\n",
    "    convert_pdf_to_markdown\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: qwen2.5vl:3b-q4_K_M\n",
      "Ollama server: http://192.168.100.80:1818\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "OLLAMA_MODEL = \"qwen2.5vl:3b-q4_K_M\"  # Change to your preferred model\n",
    "OLLAMA_BASE_URL = \"http://192.168.100.80:1818\"  # Your Ollama server URL\n",
    "PDF_PATH = \"sample_document.pdf\"  # Path to your PDF file\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Using model: {OLLAMA_MODEL}\")\n",
    "print(f\"Ollama server: {OLLAMA_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Simple conversion (output is saved in a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Conversion ===\n",
      "2025-07-05 14:47:36,901 - src.vision_processor - INFO - Connected to Ollama at http://192.168.100.80:1818\n",
      "2025-07-05 14:47:36,904 - src.vision_processor - INFO - VisionProcessor initialized with model: qwen2.5vl:3b-q4_K_M\n",
      "2025-07-05 14:47:36,906 - src.markdown_generator - DEBUG - MarkdownGenerator initialized with config: {'dpi': 300, 'vision_model_temp': 0.1, 'text_extraction_priority': True, 'image_embed_mode': 'base64', 'preserve_formatting': True, 'table_detection_threshold': 0.7, 'formula_detection_threshold': 0.8, 'min_image_size': (50, 50)}\n",
      "2025-07-05 14:47:36,914 - src.pipeline - INFO - Processing PDF with 4 pages...\n",
      "2025-07-05 14:47:36,922 - src.pipeline - INFO - Processing page 1/4\n",
      "2025-07-05 14:47:36,923 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:47:36,936 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:47:36,941 - src.pdf_analyzer - DEBUG - Text_coverage:0.1297491770806737\n",
      "2025-07-05 14:47:37,006 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:47:37,010 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:47:37,014 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:47:37,023 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.60)\n",
      "2025-07-05 14:47:37,025 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 14:47:37,032 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:47:37,502 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:47:37,507 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:47:37,509 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 148342\n",
      "2025-07-05 14:47:37,933 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:47:37,938 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:47:37,940 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:47:37,974 - httpcore.connection - DEBUG - connect_tcp.started host='192.168.100.80' port=1818 local_address=None timeout=None socket_options=None\n",
      "2025-07-05 14:47:37,986 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016624E5D850>\n",
      "2025-07-05 14:47:37,990 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:37,994 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:47:37,996 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:37,998 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:47:38,001 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:47,305 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:47:47 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:47:47,307 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,040 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:47:55,042 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:47:55,044 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:47:55,045 - src.vision_processor - DEBUG - Vision model response received, length: 773\n",
      "2025-07-05 14:47:55,047 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:47:55,053 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:47:55,056 - src.pipeline - INFO - Processing page 2/4\n",
      "2025-07-05 14:47:55,059 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:47:55,067 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:47:55,072 - src.pdf_analyzer - DEBUG - Text_coverage:0.14366892052793828\n",
      "2025-07-05 14:47:55,076 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:47:55,080 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:47:55,085 - src.pdf_analyzer - DEBUG - Has formulas:True\n",
      "2025-07-05 14:47:55,094 - src.pipeline - INFO -   Strategy: hybrid (confidence: 0.70)\n",
      "2025-07-05 14:47:55,097 - src.pipeline - INFO -   Extracting text content...\n",
      "2025-07-05 14:47:55,108 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:47:55,431 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:47:55,434 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:47:55,437 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 154081\n",
      "2025-07-05 14:47:55,812 - src.pipeline - INFO -     Extracting formulas...\n",
      "2025-07-05 14:47:55,814 - src.vision_processor - DEBUG - Extracting formulas from image\n",
      "2025-07-05 14:47:55,815 - src.vision_processor - DEBUG - Processing image content with type: formula\n",
      "2025-07-05 14:47:55,828 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,830 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:47:55,832 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:47:55,837 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:47:55,841 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:02,800 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:02 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:02,804 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,908 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:03,911 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:03,913 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:03,916 - src.vision_processor - DEBUG - Vision model response received, length: 53\n",
      "2025-07-05 14:48:03,918 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:03,920 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:03,921 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:03,937 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,939 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:03,942 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:03,946 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:03,948 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:04,512 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:04 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:04,515 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:28,311 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:28,313 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:28,314 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:28,316 - src.vision_processor - DEBUG - Vision model response received, length: 2058\n",
      "2025-07-05 14:48:28,317 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:48:28,327 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:48:28,328 - src.pipeline - INFO - Processing page 3/4\n",
      "2025-07-05 14:48:28,329 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:48:28,332 - src.pdf_analyzer - DEBUG - Has text:True\n",
      "2025-07-05 14:48:28,336 - src.pdf_analyzer - DEBUG - Text_coverage:0.06992337224219923\n",
      "2025-07-05 14:48:28,339 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:48:28,341 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:48:28,343 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:48:28,346 - src.pipeline - INFO -   Strategy: vision_only (confidence: 0.80)\n",
      "2025-07-05 14:48:28,347 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:48:28,811 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:48:28,812 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:48:28,814 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 4472495\n",
      "2025-07-05 14:48:29,082 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:29,084 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:29,086 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:29,108 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:29,110 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:29,111 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:29,112 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:29,113 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:36,219 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:36 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:36,221 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:43,884 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:48:43,886 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:48:43,889 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:48:43,891 - src.vision_processor - DEBUG - Vision model response received, length: 1056\n",
      "2025-07-05 14:48:43,892 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:48:43,894 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:48:43,896 - src.pipeline - INFO - Processing page 4/4\n",
      "2025-07-05 14:48:43,897 - src.pipeline - INFO -   Analyzing page structure...\n",
      "2025-07-05 14:48:43,902 - src.pdf_analyzer - DEBUG - Has text:False\n",
      "2025-07-05 14:48:43,906 - src.pdf_analyzer - DEBUG - Text_coverage:0.0\n",
      "2025-07-05 14:48:43,908 - src.pdf_analyzer - DEBUG - Has images:True\n",
      "2025-07-05 14:48:43,910 - src.pdf_analyzer - DEBUG - Has tables:False\n",
      "2025-07-05 14:48:43,913 - src.pdf_analyzer - DEBUG - Has formulas:False\n",
      "2025-07-05 14:48:43,917 - src.pipeline - INFO -   Strategy: vision_only (confidence: 0.80)\n",
      "2025-07-05 14:48:43,918 - src.pipeline - INFO -   Processing with vision model...\n",
      "2025-07-05 14:48:44,447 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13\n",
      "2025-07-05 14:48:44,450 - PIL.PngImagePlugin - DEBUG - STREAM b'pHYs' 41 9\n",
      "2025-07-05 14:48:44,452 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 62 188735\n",
      "2025-07-05 14:48:44,696 - src.pipeline - INFO -     Describing diagrams...\n",
      "2025-07-05 14:48:44,698 - src.vision_processor - DEBUG - Describing diagram: \n",
      "2025-07-05 14:48:44,701 - src.vision_processor - DEBUG - Processing image content with type: diagram\n",
      "2025-07-05 14:48:44,711 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:44,712 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-07-05 14:48:44,714 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:44,718 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-07-05 14:48:44,721 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-07-05 14:48:51,701 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Sat, 05 Jul 2025 12:48:51 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-07-05 14:48:51,702 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-07-05 14:49:14,519 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-07-05 14:49:14,520 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-07-05 14:49:14,521 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-07-05 14:49:14,522 - src.vision_processor - DEBUG - Vision model response received, length: 2855\n",
      "2025-07-05 14:49:14,523 - src.pipeline - INFO -   Integrating content...\n",
      "2025-07-05 14:49:14,523 - src.pipeline - INFO -   Generating markdown...\n",
      "2025-07-05 14:49:14,525 - src.pipeline - INFO - Saving results to ./output\n",
      "2025-07-05 14:49:14,529 - src.pipeline - DEBUG - Saved page 1 to output\\page_001.md\n",
      "2025-07-05 14:49:14,532 - src.pipeline - DEBUG - Saved page 2 to output\\page_002.md\n",
      "2025-07-05 14:49:14,536 - src.pipeline - DEBUG - Saved page 3 to output\\page_003.md\n",
      "2025-07-05 14:49:14,539 - src.pipeline - DEBUG - Saved page 4 to output\\page_004.md\n",
      "2025-07-05 14:49:14,541 - src.pipeline - DEBUG - Saved combined document to output\\combined_document.md\n",
      "2025-07-05 14:49:14,543 - src.pipeline - DEBUG - Saved metadata to output\\conversion_metadata.json\n",
      "2025-07-05 14:49:14,546 - src.pipeline - INFO - Successfully saved 6 files to ./output\n",
      "Conversion completed! Files saved to ./output\n",
      "  - output\\page_001.md\n",
      "  - output\\page_002.md\n",
      "  - output\\page_003.md\n",
      "  - output\\page_004.md\n",
      "  - output\\combined_document.md\n",
      "  - output\\conversion_metadata.json\n",
      "✅ Successfully converted 4 pages\n",
      "📁 Output saved to: ./output\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Simple Conversion ===\")\n",
    "\n",
    "result = convert_pdf_to_markdown(\n",
    "    pdf_path=PDF_PATH,\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    log_level=\"DEBUG\"\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(f\"✅ Successfully converted {len(result.pages)} pages\")\n",
    "    print(f\"📁 Output saved to: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"❌ Conversion failed:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"   - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Advanced usage with custom configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Advanced Configuration ===\n",
      "Pipeline Configuration:\n",
      "  analyzer: PDFAnalyzer\n",
      "  text_extractor: TextExtractor\n",
      "  vision_processor: VisionProcessor\n",
      "  integrator: ContentIntegrator\n",
      "  markdown_generator: MarkdownGenerator\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Advanced Configuration ===\")\n",
    "\n",
    "# Create custom configuration\n",
    "config = PipelineConfig()\n",
    "config.dpi = 400  # Higher resolution for better OCR\n",
    "config.vision_model_temp = 0.1  # Lower temperature for consistent output\n",
    "config.text_extraction_priority = True  # Prefer text extraction when possible\n",
    "config.preserve_formatting = True  # Maintain original formatting\n",
    "config.image_embed_mode = \"base64\"  # Embed images as base64\n",
    "\n",
    "# Initialize pipeline with custom config\n",
    "pipeline = PDFToMarkdownPipeline(\n",
    "    ollama_model=OLLAMA_MODEL,\n",
    "    ollama_base_url=OLLAMA_BASE_URL,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Show pipeline information\n",
    "print(\"Pipeline Configuration:\")\n",
    "info = pipeline.get_pipeline_info()\n",
    "for component, name in info[\"components\"].items():\n",
    "    print(f\"  {component}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Process single page for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Page Processing ===\n",
      "Analyzing first page...\n",
      "Page Analysis:\n",
      "  - Has extractable text: True\n",
      "  - Text coverage: 0.12\n",
      "  - Has images: False\n",
      "  - Has tables: False\n",
      "  - Has formulas: False\n",
      "  - Layout complexity: 0.90\n",
      "  - Recommended strategy: vision_only\n",
      "  - Confidence: 0.80\n",
      "\n",
      "Processing page...\n",
      "  Analyzing page structure...\n",
      "  Strategy: vision_only (confidence: 0.80)\n",
      "  Processing with vision model...\n",
      "    General content extraction...\n",
      "  Integrating content...\n",
      "  Generating markdown...\n",
      "\n",
      "Generated markdown (0 characters):\n",
      "==================================================\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Single Page Processing ===\")\n",
    "\n",
    "import fitz\n",
    "\n",
    "# Open PDF and process first page only\n",
    "with  fitz.open(PDF_PATH) as doc:\n",
    "    if doc.page_count > 0:\n",
    "        first_page = doc[0]\n",
    "        \n",
    "        print(\"Analyzing first page...\")\n",
    "        analysis = pipeline.analyzer.analyze_page_content(first_page)\n",
    "        \n",
    "        print(f\"Page Analysis:\")\n",
    "        print(f\"  - Has extractable text: {analysis.has_extractable_text}\")\n",
    "        print(f\"  - Text coverage: {analysis.text_coverage:.2f}\")\n",
    "        print(f\"  - Has images: {analysis.has_images}\")\n",
    "        print(f\"  - Has tables: {analysis.has_tables}\")\n",
    "        print(f\"  - Has formulas: {analysis.has_formulas}\")\n",
    "        print(f\"  - Layout complexity: {analysis.layout_complexity:.2f}\")\n",
    "        print(f\"  - Recommended strategy: {analysis.strategy.value}\")\n",
    "        print(f\"  - Confidence: {analysis.confidence:.2f}\")\n",
    "        \n",
    "        # Process the page\n",
    "        print(\"\\nProcessing page...\")\n",
    "        page_markdown = pipeline.convert_page(first_page)\n",
    "        \n",
    "        print(f\"\\nGenerated markdown ({len(page_markdown)} characters):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(page_markdown[:500] + \"...\" if len(page_markdown) > 500 else page_markdown)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Batch processing with custom content handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch Processing with Content Analysis ===\n",
      "Analyzing PDF structure (1 pages)...\n",
      "Page 1: vision_only (conf: 0.80, complex: 0.90)\n",
      "\n",
      "Strategy Distribution:\n",
      "  vision_only: 1 pages\n",
      "\n",
      "Average layout complexity: 0.90\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Batch Processing with Content Analysis ===\")\n",
    "\n",
    "def analyze_pdf_structure(pdf_path: str):\n",
    "    \"\"\"Analyze entire PDF structure before processing\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        analyses = {}\n",
    "        \n",
    "        print(f\"Analyzing PDF structure ({doc.page_count} pages)...\")\n",
    "        \n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc[page_num]\n",
    "            analysis = pipeline.analyzer.analyze_page_content(page)\n",
    "            analyses[page_num] = analysis\n",
    "            \n",
    "            print(f\"Page {page_num + 1}: {analysis.strategy.value} \"\n",
    "                f\"(conf: {analysis.confidence:.2f}, \"\n",
    "                f\"complex: {analysis.layout_complexity:.2f})\")\n",
    "    \n",
    "    return analyses\n",
    "\n",
    "# Analyze structure first\n",
    "if Path(PDF_PATH).exists():\n",
    "    pdf_analyses = analyze_pdf_structure(PDF_PATH)\n",
    "    \n",
    "    # Show summary statistics\n",
    "    strategies = [a.strategy.value for a in pdf_analyses.values()]\n",
    "    strategy_counts = {s: strategies.count(s) for s in set(strategies)}\n",
    "    \n",
    "    print(\"\\nStrategy Distribution:\")\n",
    "    for strategy, count in strategy_counts.items():\n",
    "        print(f\"  {strategy}: {count} pages\")\n",
    "    \n",
    "    avg_complexity = sum(a.layout_complexity for a in pdf_analyses.values()) / len(pdf_analyses)\n",
    "    print(f\"\\nAverage layout complexity: {avg_complexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5: Testing different vision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "\n",
      "Testing model: llama3.2-vision:11b\n",
      "  Analyzing page structure...\n",
      "  Strategy: vision_only (confidence: 0.80)\n",
      "  Processing with vision model...\n",
      "    Describing diagrams...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Model Comparison ===\")\n",
    "\n",
    "# List of models to test (uncomment available models)\n",
    "test_models = [\n",
    "    \"llama3.2-vision:11b\",\n",
    "    \"qwen2.5vl:3b-q4_K_M\",\n",
    "    # \"llava:13b\",\n",
    "    # \"bakllava\",\n",
    "]\n",
    "\n",
    "def test_model_performance(models: list, test_pdf: str):\n",
    "    \"\"\"Test different models on the same page\"\"\"\n",
    "    if not Path(test_pdf).exists():\n",
    "        print(f\"Test PDF not found: {test_pdf}\")\n",
    "        return\n",
    "    \n",
    "    with fitz.open(test_pdf) as doc:\n",
    "        test_page = doc[0]  # Use first page for testing\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for model in models:\n",
    "            try:\n",
    "                print(f\"\\nTesting model: {model}\")\n",
    "                \n",
    "                # Create pipeline with this model\n",
    "                test_pipeline = PDFToMarkdownPipeline(model, OLLAMA_BASE_URL)\n",
    "                \n",
    "                # Process page\n",
    "                markdown = test_pipeline.convert_page(test_page)\n",
    "                \n",
    "                results[model] = {\n",
    "                    \"success\": True,\n",
    "                    \"length\": len(markdown),\n",
    "                    \"preview\": markdown[:200] + \"...\" if len(markdown) > 200 else markdown\n",
    "                }\n",
    "                \n",
    "                print(f\"  ✅ Success - {len(markdown)} chars\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[model] = {\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "                print(f\"  ❌ Failed: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run model comparison (only if you have multiple models)\n",
    "if len(test_models) > 1:\n",
    "    model_results = test_model_performance(test_models, PDF_PATH)\n",
    "    \n",
    "    print(\"\\n=== Model Comparison Results ===\")\n",
    "    for model, result in model_results.items():\n",
    "        if result[\"success\"]:\n",
    "            print(f\"{model}: {result['length']} characters\")\n",
    "        else:\n",
    "            print(f\"{model}: FAILED - {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6: Error handling and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/fberge/OneDrive - Studiecentrum voor Kernenergie/Documents/python/vision-parse/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Error Handling Examples ===\")\n",
    "\n",
    "# Test with non-existent file\n",
    "print(\"Testing with non-existent file...\")\n",
    "bad_result = convert_pdf_to_markdown(\"nonexistent.pdf\", OLLAMA_MODEL, OLLAMA_BASE_URL)\n",
    "print(f\"Expected failure: {not bad_result.success}\")\n",
    "\n",
    "# Test with wrong Ollama URL\n",
    "print(\"\\nTesting with wrong Ollama URL...\")\n",
    "try:\n",
    "    bad_pipeline = PDFToMarkdownPipeline(OLLAMA_MODEL, \"http://localhost:99999\")\n",
    "    # This will fail when we try to use the vision processor\n",
    "    print(\"Pipeline created (will fail on actual processing)\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "\n",
    "# %%\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PDF to Markdown Pipeline Demo Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Path(OUTPUT_DIR).exists():\n",
    "    output_files = list(Path(OUTPUT_DIR).glob(\"*\"))\n",
    "    print(f\"\\nGenerated files in {OUTPUT_DIR}:\")\n",
    "    for file in output_files:\n",
    "        size = file.stat().st_size if file.is_file() else 0\n",
    "        print(f\"  📄 {file.name} ({size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nPipeline ready for production use!\")\n",
    "print(f\"💡 Tip: Adjust PipelineConfig settings for your specific needs\")\n",
    "print(f\"🔧 Remember to tune vision model temperature and DPI settings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
